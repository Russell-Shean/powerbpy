[
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html",
    "href": "example_dashboards/Sanky Chart and Table/index.html",
    "title": "Sanky Chart and Table",
    "section": "",
    "text": "I used the PowerBpy python module to recreate an sanky chart and table dashboard from the Workout Wednesday Group challenge. Here’s a screenshot of the original dashboard (left) and the dashboard I recreated using Power Bpy (right). (It appears that the data has changed since the original author created his dashboard, so my version and his look a bit different because the data is a bit different, but the overall format is pretty similiar). The rest of the blog will describe key parts of the code I used to make the dashboard. The full code is available here."
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#assumptions",
    "href": "example_dashboards/Sanky Chart and Table/index.html#assumptions",
    "title": "Sanky Chart and Table",
    "section": "Assumptions",
    "text": "Assumptions\nThis example assumes that you already have python installed and setup and that you know how to install python modules such as pandas.If you don’t, please refer to basic setup instructions on this page or find one of the many great resources online that explains how to install python packages."
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#obtain-and-prepare-data",
    "href": "example_dashboards/Sanky Chart and Table/index.html#obtain-and-prepare-data",
    "title": "Sanky Chart and Table",
    "section": "Obtain and prepare data",
    "text": "Obtain and prepare data\nOne of the central assumptions built into the PowerBpy package is that you’d prefer to write python code over using Power BI. Therefore this example will avoid writing any M or DAX and will instead use python to extract, load and transform the data. Once the data is ready will use PowerBpy to create the dashboard."
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#download-data",
    "href": "example_dashboards/Sanky Chart and Table/index.html#download-data",
    "title": "Sanky Chart and Table",
    "section": "Download Data",
    "text": "Download Data\nThe data for this example is stored as an online zip file. The following code downloads the zip file and extracts it into a local directory.\nimport requests\nimport py7zr\nimport os\nimport tempfile\n\n'''\nThis script downloads the data from Github and \nthen extracts the individual datasets from the compressed archive file. \n\n\n\n'''\n\n# step 1: obtain data from github --------------------------------------------------------------\n\n# Define paths\ndataset_url = \"https://github.com/sql-bi/Contoso-Data-Generator-V2-Data/releases/download/ready-to-use-data/csv-10k.7z\" \ndata_destination_dir = \"data\"\n\n\n# make sure the folder exists\nos.makedirs(data_destination_dir, exist_ok=True)\n\n# download the zip file from the internet\nresponse = requests.get(dataset_url, stream=True)\nresponse.raise_for_status()\n\n# write to file\nwith tempfile.NamedTemporaryFile(suffix=\".7z\", delete=False) as tmp_file:\n    with open(tmp_file.name, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n\n\n# extract the data \nwith py7zr.SevenZipFile(tmp_file.name, mode=\"r\") as z:\n    z.extractall(path=data_destination_dir)"
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#process-data",
    "href": "example_dashboards/Sanky Chart and Table/index.html#process-data",
    "title": "Sanky Chart and Table",
    "section": "Process data",
    "text": "Process data"
  },
  {
    "objectID": "reference/add_chart.html",
    "href": "reference/add_chart.html",
    "title": "add_chart",
    "section": "",
    "text": "add_chart\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\nadd_chart.add_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    chart_type,\n    data_source,\n    chart_title,\n    x_axis_title,\n    y_axis_title,\n    x_axis_var,\n    y_axis_var,\n    y_axis_var_aggregation_type,\n    x_position,\n    y_position,\n    height,\n    width,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str chart_id: Please choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str chart_type: The type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ] :param str data_source: The name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\n:param str chart_title: Give your chart an informative title!:D :param str x_axis_title: Text to display on the x axis :param str y_axis_title: Text to display on the y axis\n:param str x_axis_var: Column name of a column from data_source that you want to use for the x axis of the chart :param str y_axis_var: Column name of a column from data_source that you want to use for the y axis of the chart :param str y_axis_var_aggregation_type: Type of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\n:param int x_position: The x coordinate of where you want to put the chart on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\n:param int height: Height of chart on the page :param int width: Width of chart on the page\n:param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_chart"
    ]
  },
  {
    "objectID": "reference/add_chart.html#functions",
    "href": "reference/add_chart.html#functions",
    "title": "add_chart",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\nadd_chart.add_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    chart_type,\n    data_source,\n    chart_title,\n    x_axis_title,\n    y_axis_title,\n    x_axis_var,\n    y_axis_var,\n    y_axis_var_aggregation_type,\n    x_position,\n    y_position,\n    height,\n    width,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str chart_id: Please choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str chart_type: The type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ] :param str data_source: The name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\n:param str chart_title: Give your chart an informative title!:D :param str x_axis_title: Text to display on the x axis :param str y_axis_title: Text to display on the y axis\n:param str x_axis_var: Column name of a column from data_source that you want to use for the x axis of the chart :param str y_axis_var: Column name of a column from data_source that you want to use for the y axis of the chart :param str y_axis_var_aggregation_type: Type of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\n:param int x_position: The x coordinate of where you want to put the chart on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\n:param int height: Height of chart on the page :param int width: Width of chart on the page\n:param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_chart"
    ]
  },
  {
    "objectID": "reference/add_ADLS_csv.html",
    "href": "reference/add_ADLS_csv.html",
    "title": "add_ADLS_csv",
    "section": "",
    "text": "add_ADLS_csv\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_csv_from_blob\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\nadd_ADLS_csv.add_csv_from_blob(\n    dashboard_path,\n    account_url,\n    blob_name,\n    data_path,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    SAS_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\naccount_url\nstr\nThe url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field\nrequired\n\n\nblob_name\nstr\nThe name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field.\nrequired\n\n\ndata_path\nstr\nThe relative path to the file you want to load from the blob. It should be relative to blob_name\nrequired\n\n\ntenant_id\nstr\nThe tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default).\nNone\n\n\nuse_saved_storage_key\nboolean\nThis optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD.\nFalse\n\n\nSAS_url\nstr\nA limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature”\nNone\n\n\nstorage_account_key\nstr\nPlease, Please, Please do not use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nNone DO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function. This function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file. Thanks Microsoft for yet again doing a great job with backward compatibility lol. Dashboards created with the create_blank_dashboard() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this."
  },
  {
    "objectID": "reference/add_ADLS_csv.html#functions",
    "href": "reference/add_ADLS_csv.html#functions",
    "title": "add_ADLS_csv",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_csv_from_blob\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\nadd_ADLS_csv.add_csv_from_blob(\n    dashboard_path,\n    account_url,\n    blob_name,\n    data_path,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    SAS_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\naccount_url\nstr\nThe url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field\nrequired\n\n\nblob_name\nstr\nThe name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field.\nrequired\n\n\ndata_path\nstr\nThe relative path to the file you want to load from the blob. It should be relative to blob_name\nrequired\n\n\ntenant_id\nstr\nThe tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default).\nNone\n\n\nuse_saved_storage_key\nboolean\nThis optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD.\nFalse\n\n\nSAS_url\nstr\nA limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature”\nNone\n\n\nstorage_account_key\nstr\nPlease, Please, Please do not use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nNone DO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function. This function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file. Thanks Microsoft for yet again doing a great job with backward compatibility lol. Dashboards created with the create_blank_dashboard() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this."
  },
  {
    "objectID": "reference/add_card.html",
    "href": "reference/add_card.html",
    "title": "add_card",
    "section": "",
    "text": "add_card\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_card\nAdd a card to a page\n\n\n\n\n\nadd_card.add_card(\n    data_source,\n    measure_name,\n    dashboard_path,\n    page_id,\n    card_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    title=None,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a card to a page\n:param str data_source: This is the name of the dataset that you want to use to populate the card with :param str measure_name: This is the name of the measure (or variable) name you want to use to populate the card with :param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the card to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str card_id: Please choose a unique id to use to identify the card. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param int height: Height of card on the page :param int width: Width of card on the page\n:param int x_position: The x coordinate of where you want to put the card on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the card on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n:param str title: An optional title to add to the card. :param str text_align: How would you like the text aligned (available options: “left”, “right”, “center”) :param str font_weight: This is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”] :param int font_size: The font size in pts. Must be a whole integer. Defaults to 32 pt :param str font_color: Hex code for the font color you’d like to use. Defaults to black (#000000) :param str background_color: Hex code for the background color of the card. Defaults to None (transparent) :param str parent_group_id: This should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group.\nThis function creates a new card on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_card"
    ]
  },
  {
    "objectID": "reference/add_card.html#functions",
    "href": "reference/add_card.html#functions",
    "title": "add_card",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_card\nAdd a card to a page\n\n\n\n\n\nadd_card.add_card(\n    data_source,\n    measure_name,\n    dashboard_path,\n    page_id,\n    card_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    title=None,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a card to a page\n:param str data_source: This is the name of the dataset that you want to use to populate the card with :param str measure_name: This is the name of the measure (or variable) name you want to use to populate the card with :param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the card to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str card_id: Please choose a unique id to use to identify the card. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param int height: Height of card on the page :param int width: Width of card on the page\n:param int x_position: The x coordinate of where you want to put the card on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the card on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n:param str title: An optional title to add to the card. :param str text_align: How would you like the text aligned (available options: “left”, “right”, “center”) :param str font_weight: This is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”] :param int font_size: The font size in pts. Must be a whole integer. Defaults to 32 pt :param str font_color: Hex code for the font color you’d like to use. Defaults to black (#000000) :param str background_color: Hex code for the background color of the card. Defaults to None (transparent) :param str parent_group_id: This should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group.\nThis function creates a new card on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_card"
    ]
  },
  {
    "objectID": "reference/create_tmdl.html",
    "href": "reference/create_tmdl.html",
    "title": "create_tmdl",
    "section": "",
    "text": "create_tmdl\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_tmdl\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\ncreate_tmdl.create_tmdl(dashboard_path, dataset_name, dataset_id, dataset)\nAn internally called function that creates a TMDL file from a pandas dataframe\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str dataset_name: The name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”. :param str dataset_id: The dataset’s UUID, this will be generated by the outer level function that calls create_tmdl(). :param DataFrame dataset: This is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\n:returns: col_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work.\nThis function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "create_tmdl"
    ]
  },
  {
    "objectID": "reference/create_tmdl.html#functions",
    "href": "reference/create_tmdl.html#functions",
    "title": "create_tmdl",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_tmdl\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\ncreate_tmdl.create_tmdl(dashboard_path, dataset_name, dataset_id, dataset)\nAn internally called function that creates a TMDL file from a pandas dataframe\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str dataset_name: The name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”. :param str dataset_id: The dataset’s UUID, this will be generated by the outer level function that calls create_tmdl(). :param DataFrame dataset: This is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\n:returns: col_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work.\nThis function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "create_tmdl"
    ]
  },
  {
    "objectID": "reference/generate_bin_ranges.html",
    "href": "reference/generate_bin_ranges.html",
    "title": "generate_bin_ranges",
    "section": "",
    "text": "generate_bin_ranges\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_bin_measures\nAn internally called function that adds bin measures to a TMDL file\n\n\n\n\n\ngenerate_bin_ranges.add_bin_measures(\n    dashboard_path,\n    dataset_name,\n    color_var,\n    percentile_bin_breaks,\n    color_palette,\n    filtering_var,\n    location_var,\n    data_filtering_condition=None,\n)\nAn internally called function that adds bin measures to a TMDL file\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str dataset_name: The name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”. :param str dataset_id: The dataset’s UUID, this will be generated by the outer level function that calls create_tmdl(). :param DataFrame dataset: This is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl(). :param dict data_filtering_condition: This is a key value pair for filtering long data. The key should be the column you want to look for and the value should be the value in that column that you want to filter for.For example if the original data has a column called metric with a variety of different metrics and you want to filter the dataset for only rows where the column is equal to “adj_rate”, you should provide the following {“metric”:“adj_rate”}\n:returns: col_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work.\nThis function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "generate_bin_ranges"
    ]
  },
  {
    "objectID": "reference/generate_bin_ranges.html#functions",
    "href": "reference/generate_bin_ranges.html#functions",
    "title": "generate_bin_ranges",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_bin_measures\nAn internally called function that adds bin measures to a TMDL file\n\n\n\n\n\ngenerate_bin_ranges.add_bin_measures(\n    dashboard_path,\n    dataset_name,\n    color_var,\n    percentile_bin_breaks,\n    color_palette,\n    filtering_var,\n    location_var,\n    data_filtering_condition=None,\n)\nAn internally called function that adds bin measures to a TMDL file\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str dataset_name: The name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”. :param str dataset_id: The dataset’s UUID, this will be generated by the outer level function that calls create_tmdl(). :param DataFrame dataset: This is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl(). :param dict data_filtering_condition: This is a key value pair for filtering long data. The key should be the column you want to look for and the value should be the value in that column that you want to filter for.For example if the original data has a column called metric with a variety of different metrics and you want to filter the dataset for only rows where the column is equal to “adj_rate”, you should provide the following {“metric”:“adj_rate”}\n:returns: col_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work.\nThis function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "generate_bin_ranges"
    ]
  },
  {
    "objectID": "reference/add_shape_map.html",
    "href": "reference/add_shape_map.html",
    "title": "add_shape_map",
    "section": "",
    "text": "add_shape_map\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_shape_map\nAdd a map to a page\n\n\n\n\n\nadd_shape_map.add_shape_map(\n    dashboard_path,\n    page_id,\n    map_id,\n    data_source,\n    shape_file_path,\n    map_title,\n    location_var,\n    color_var,\n    color_palette,\n    height,\n    width,\n    x_position,\n    y_position,\n    add_legend=True,\n    static_bin_breaks=None,\n    percentile_bin_breaks=None,\n    filtering_var=None,\n    z_position=6000,\n    tab_order=-1001,\n)\nAdd a map to a page\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the map to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str map_id: Please choose a unique id to use to identify the map. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str data_source: The name of the dataset you want to use to build the map. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard. :param str shape_file_path: A path to a shapefile that you want to use to build the map. This shape file will be added to the registered resources.\n:param str map_title: The title you want to put above the map. :param str location_var: The name of the column in data_source that you want to use for the location variable on the map :param str color_var: The name of the column in data_source that you want to use for the color variable on the map :param str filtering_var: Optional. The name of a column in data source that you want to use to filter the color variable on the map. This must be supplied if providing percentile_bin_breaks. If you want to use percentiles without filtering (ie on static data), you should calculate the percentiles yourself and pass them to static_bin_breaks. Do not provide both static_bin_breaks and a filtering_var.\n:param list static_bin_breaks: This should be a list of numbers that you want to use to create bins in your data. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. The function will create bins between the first and second number, second and third, third and fourth, etc. A filtering_var cannot be provided if static_bin_breaks is provided. Use percentile bin breaks instead. :param list color_palatte: A list of hex codes to use to color your data. There should be one fewer than the number of entries in static_bin_breaks :param bool add_legend: True or False, would you like to add the default legend? (By default legend, I mean this function’s default, not the Power BI default) :param list static_bin_breaks: This should be a list of numbers that you want to use to create bins in your data. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. The function will create bins between the first and second number, second and third, third and fourth, etc. :param list percentile_bin_breaks: This should be a list of percentiles between 0 and 1 that you want to us to create bins in your data. If provided, a filtering_var must also be provided. This will create power BI measures that dynamically update when the data is filtered by things such as slicers. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. Here’s an example use case: to create 5 equal sized bins pass this list: [0,0.2,0.4,0.6,0.8,1]\n:param int height: Height of map on the page :param int width: Width of map on the page\n:param int x_position: The x coordinate of where you want to put the map on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the map on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\nThis function creates a new cloropleth map on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_shape_map"
    ]
  },
  {
    "objectID": "reference/add_shape_map.html#functions",
    "href": "reference/add_shape_map.html#functions",
    "title": "add_shape_map",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_shape_map\nAdd a map to a page\n\n\n\n\n\nadd_shape_map.add_shape_map(\n    dashboard_path,\n    page_id,\n    map_id,\n    data_source,\n    shape_file_path,\n    map_title,\n    location_var,\n    color_var,\n    color_palette,\n    height,\n    width,\n    x_position,\n    y_position,\n    add_legend=True,\n    static_bin_breaks=None,\n    percentile_bin_breaks=None,\n    filtering_var=None,\n    z_position=6000,\n    tab_order=-1001,\n)\nAdd a map to a page\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the map to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str map_id: Please choose a unique id to use to identify the map. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str data_source: The name of the dataset you want to use to build the map. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard. :param str shape_file_path: A path to a shapefile that you want to use to build the map. This shape file will be added to the registered resources.\n:param str map_title: The title you want to put above the map. :param str location_var: The name of the column in data_source that you want to use for the location variable on the map :param str color_var: The name of the column in data_source that you want to use for the color variable on the map :param str filtering_var: Optional. The name of a column in data source that you want to use to filter the color variable on the map. This must be supplied if providing percentile_bin_breaks. If you want to use percentiles without filtering (ie on static data), you should calculate the percentiles yourself and pass them to static_bin_breaks. Do not provide both static_bin_breaks and a filtering_var.\n:param list static_bin_breaks: This should be a list of numbers that you want to use to create bins in your data. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. The function will create bins between the first and second number, second and third, third and fourth, etc. A filtering_var cannot be provided if static_bin_breaks is provided. Use percentile bin breaks instead. :param list color_palatte: A list of hex codes to use to color your data. There should be one fewer than the number of entries in static_bin_breaks :param bool add_legend: True or False, would you like to add the default legend? (By default legend, I mean this function’s default, not the Power BI default) :param list static_bin_breaks: This should be a list of numbers that you want to use to create bins in your data. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. The function will create bins between the first and second number, second and third, third and fourth, etc. :param list percentile_bin_breaks: This should be a list of percentiles between 0 and 1 that you want to us to create bins in your data. If provided, a filtering_var must also be provided. This will create power BI measures that dynamically update when the data is filtered by things such as slicers. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. Here’s an example use case: to create 5 equal sized bins pass this list: [0,0.2,0.4,0.6,0.8,1]\n:param int height: Height of map on the page :param int width: Width of map on the page\n:param int x_position: The x coordinate of where you want to put the map on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the map on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\nThis function creates a new cloropleth map on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_shape_map"
    ]
  },
  {
    "objectID": "reference/create_new_page.html",
    "href": "reference/create_new_page.html",
    "title": "create_new_page",
    "section": "",
    "text": "create_new_page\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_new_page\nCreate a new blank dashboard page\n\n\n\n\n\ncreate_new_page.add_new_page(\n    dashboard_path,\n    page_name,\n    title=None,\n    subtitle=None,\n    displayOption = \"FitToPage\"\n)\nCreate a new blank dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_name\nstr\nThe display name for the page you just created. This is differnt from the page_id which is only used internally.\nrequired\n\n\ntitle\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\nsub_title\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nrequired\n\n\ndisplayOption\nstr\nDefault way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize.\nFitToPage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nnew_page_id: The unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list."
  },
  {
    "objectID": "reference/create_new_page.html#functions",
    "href": "reference/create_new_page.html#functions",
    "title": "create_new_page",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_new_page\nCreate a new blank dashboard page\n\n\n\n\n\ncreate_new_page.add_new_page(\n    dashboard_path,\n    page_name,\n    title=None,\n    subtitle=None,\n    displayOption = \"FitToPage\"\n)\nCreate a new blank dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_name\nstr\nThe display name for the page you just created. This is differnt from the page_id which is only used internally.\nrequired\n\n\ntitle\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\nsub_title\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nrequired\n\n\ndisplayOption\nstr\nDefault way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize.\nFitToPage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nnew_page_id: The unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list."
  },
  {
    "objectID": "reference/create_blank_dashboard.html",
    "href": "reference/create_blank_dashboard.html",
    "title": "create_blank_dashboard",
    "section": "",
    "text": "create_blank_dashboard\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_new_dashboard\nCreate a new dashboard in the specified folder\n\n\n\n\n\ncreate_blank_dashboard.create_new_dashboard(parent_dir, report_name)\nCreate a new dashboard in the specified folder\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nparent_dir\nstr\nThe path to the directory where you want to store the new dashboard\nrequired\n\n\nreport_name\nstr\nName of the report. This function creates a power BI report in the specified parent directory. The dashboard can be opened and edited in Power BI desktop like normal, or be further modified progromatically using other functions in this package. The function creates a folder with the name report_name inside parent_dir with all the dashboard’s files. The dashboard uses a .pbip/.pbir format with TMDL enabled. To publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing These annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions. (.pbip uses mimified json by default and throws an error when it’s given unpacked json). This dashboard turns off time intelligence and relationship autodection off by default If you have the option I would recommend looking into a different web development framework (shiny, flask, etc) for building dashboards. Only use this package if you have to :D\nrequired"
  },
  {
    "objectID": "reference/create_blank_dashboard.html#functions",
    "href": "reference/create_blank_dashboard.html#functions",
    "title": "create_blank_dashboard",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_new_dashboard\nCreate a new dashboard in the specified folder\n\n\n\n\n\ncreate_blank_dashboard.create_new_dashboard(parent_dir, report_name)\nCreate a new dashboard in the specified folder\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nparent_dir\nstr\nThe path to the directory where you want to store the new dashboard\nrequired\n\n\nreport_name\nstr\nName of the report. This function creates a power BI report in the specified parent directory. The dashboard can be opened and edited in Power BI desktop like normal, or be further modified progromatically using other functions in this package. The function creates a folder with the name report_name inside parent_dir with all the dashboard’s files. The dashboard uses a .pbip/.pbir format with TMDL enabled. To publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing These annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions. (.pbip uses mimified json by default and throws an error when it’s given unpacked json). This dashboard turns off time intelligence and relationship autodection off by default If you have the option I would recommend looking into a different web development framework (shiny, flask, etc) for building dashboards. Only use this package if you have to :D\nrequired"
  },
  {
    "objectID": "reference/create_new_chart.html",
    "href": "reference/create_new_chart.html",
    "title": "create_new_chart",
    "section": "",
    "text": "create_new_chart\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\ncreate_new_chart.add_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    chart_type,\n    data_source,\n    chart_title,\n    x_axis_title,\n    y_axis_title,\n    x_axis_var,\n    y_axis_var,\n    y_axis_var_aggregation_type,\n    x_position,\n    y_position,\n    height,\n    width,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nchart_id\nstr\nPlease choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nchart_type\nstr\nThe type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ]\nrequired\n\n\ndata_source\nstr\nThe name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\nrequired\n\n\nchart_title\nstr\nGive your chart an informative title!:D\nrequired\n\n\nx_axis_title\nstr\nText to display on the x axis\nrequired\n\n\ny_axis_title\nstr\nText to display on the y axis\nrequired\n\n\nx_axis_var\nstr\nColumn name of a column from data_source that you want to use for the x axis of the chart\nrequired\n\n\ny_axis_var\nstr\nColumn name of a column from data_source that you want to use for the y axis of the chart\nrequired\n\n\ny_axis_var_aggregation_type\nstr\nType of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\nheight\nint\nHeight of chart on the page\nrequired\n\n\nwidth\nint\nWidth of chart on the page\nrequired\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000"
  },
  {
    "objectID": "reference/create_new_chart.html#functions",
    "href": "reference/create_new_chart.html#functions",
    "title": "create_new_chart",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\ncreate_new_chart.add_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    chart_type,\n    data_source,\n    chart_title,\n    x_axis_title,\n    y_axis_title,\n    x_axis_var,\n    y_axis_var,\n    y_axis_var_aggregation_type,\n    x_position,\n    y_position,\n    height,\n    width,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nchart_id\nstr\nPlease choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nchart_type\nstr\nThe type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ]\nrequired\n\n\ndata_source\nstr\nThe name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\nrequired\n\n\nchart_title\nstr\nGive your chart an informative title!:D\nrequired\n\n\nx_axis_title\nstr\nText to display on the x axis\nrequired\n\n\ny_axis_title\nstr\nText to display on the y axis\nrequired\n\n\nx_axis_var\nstr\nColumn name of a column from data_source that you want to use for the x axis of the chart\nrequired\n\n\ny_axis_var\nstr\nColumn name of a column from data_source that you want to use for the y axis of the chart\nrequired\n\n\ny_axis_var_aggregation_type\nstr\nType of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\nheight\nint\nHeight of chart on the page\nrequired\n\n\nwidth\nint\nWidth of chart on the page\nrequired\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000"
  },
  {
    "objectID": "reference/add_sanky_chart.html",
    "href": "reference/add_sanky_chart.html",
    "title": "add_sanky_chart",
    "section": "",
    "text": "add_sanky_chart\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_sanky_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\nadd_sanky_chart.add_sanky_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    data_source,\n    starting_var,\n    starting_var_values,\n    ending_var,\n    ending_var_values,\n    values_from_var,\n    x_position,\n    y_position,\n    height,\n    width,\n    chart_title,\n    link_colors=None,\n    alt_text='A sankey chart',\n    chart_title_font_size=17,\n    label_font_size=20,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the Sanky chart to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str chart_id: Please choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str chart_type: The type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ] :param str data_source: The name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\n:param str starting_var: Which variable from the data_source, do you want to use for the left side of the sanky chart? :param list starting_var_values: Which individual values do you want to use for the left side of the sanky chart? In general, this will probably mean all the unique values in the starting_var column. This function is setup to assume that you already know the structure of your data and can pass a list of unique values. :param str ending_var: Which variable from the data_source, do you want to use for the right side of the sanky chart? :param list ending_var_values: Which individual values do you want to use for the right side of the sanky chart? In general, this will probably mean all the unique values in the starting_var column. This function is setup to assume that you already know the structure of your data and can pass a list of unique values. :param values_from_var: This is the variable that you want to count unique instances of as grouped by starting and ending variables. For now it only counts unique variables, but I’d like to add the option to provide a sum too\n:param str chart_title: Give your chart an informative title!:D :param str alt_text: Alternate text for the visualization can be provided as an argument. This is important for screen readers (accesibility) or if the visualization doesn’t load properly. :param int chart_title_font_size: Font size for chart title :param int label_font_size: Font size for the labels on the various sanky nodes :param list link_colors: Here you can provide a list of Hex code colors for the connections between the different categories in the Sanky chart. In general this should be equal to the length of starting_var_values multiplied by the length of ending_var_values. If an argument is not provided the function assigns default colors.\n:param str x_axis_var: Column name of a column from data_source that you want to use for the x axis of the chart :param str y_axis_var: Column name of a column from data_source that you want to use for the y axis of the chart :param str y_axis_var_aggregation_type: Type of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\n:param int x_position: The x coordinate of where you want to put the chart on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\n:param int height: Height of chart on the page :param int width: Width of chart on the page\n:param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_sanky_chart"
    ]
  },
  {
    "objectID": "reference/add_sanky_chart.html#functions",
    "href": "reference/add_sanky_chart.html#functions",
    "title": "add_sanky_chart",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_sanky_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\nadd_sanky_chart.add_sanky_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    data_source,\n    starting_var,\n    starting_var_values,\n    ending_var,\n    ending_var_values,\n    values_from_var,\n    x_position,\n    y_position,\n    height,\n    width,\n    chart_title,\n    link_colors=None,\n    alt_text='A sankey chart',\n    chart_title_font_size=17,\n    label_font_size=20,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the Sanky chart to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str chart_id: Please choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str chart_type: The type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ] :param str data_source: The name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\n:param str starting_var: Which variable from the data_source, do you want to use for the left side of the sanky chart? :param list starting_var_values: Which individual values do you want to use for the left side of the sanky chart? In general, this will probably mean all the unique values in the starting_var column. This function is setup to assume that you already know the structure of your data and can pass a list of unique values. :param str ending_var: Which variable from the data_source, do you want to use for the right side of the sanky chart? :param list ending_var_values: Which individual values do you want to use for the right side of the sanky chart? In general, this will probably mean all the unique values in the starting_var column. This function is setup to assume that you already know the structure of your data and can pass a list of unique values. :param values_from_var: This is the variable that you want to count unique instances of as grouped by starting and ending variables. For now it only counts unique variables, but I’d like to add the option to provide a sum too\n:param str chart_title: Give your chart an informative title!:D :param str alt_text: Alternate text for the visualization can be provided as an argument. This is important for screen readers (accesibility) or if the visualization doesn’t load properly. :param int chart_title_font_size: Font size for chart title :param int label_font_size: Font size for the labels on the various sanky nodes :param list link_colors: Here you can provide a list of Hex code colors for the connections between the different categories in the Sanky chart. In general this should be equal to the length of starting_var_values multiplied by the length of ending_var_values. If an argument is not provided the function assigns default colors.\n:param str x_axis_var: Column name of a column from data_source that you want to use for the x axis of the chart :param str y_axis_var: Column name of a column from data_source that you want to use for the y axis of the chart :param str y_axis_var_aggregation_type: Type of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\n:param int x_position: The x coordinate of where you want to put the chart on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\n:param int height: Height of chart on the page :param int width: Width of chart on the page\n:param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_sanky_chart"
    ]
  },
  {
    "objectID": "reference/add_table.html",
    "href": "reference/add_table.html",
    "title": "add_table",
    "section": "",
    "text": "add_table\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_table\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\nadd_table.add_table(\n    dashboard_path,\n    page_id,\n    table_id,\n    data_source,\n    variables,\n    x_position,\n    y_position,\n    height,\n    width,\n    add_totals_row=False,\n    table_title=None,\n    column_widths=None,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the background image to. If you used this package’s functions to create pages it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str chart_id: Please choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str data_source: The name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard. :param list variables: The variables from the table that you want to include\n:param str table_title: Give your table an informative title!:D\n:param dict column_widths: Optional. Provide the width of columns. Provide the widths as a dictionary with column names as keys and widths as values. :param int x_position: The x coordinate of where you want to put the table on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the table on the page. Origin is page’s top left corner.\n:param int height: Height of table on the page :param int width: Width of table on the page\n:param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_table"
    ]
  },
  {
    "objectID": "reference/add_table.html#functions",
    "href": "reference/add_table.html#functions",
    "title": "add_table",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_table\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\nadd_table.add_table(\n    dashboard_path,\n    page_id,\n    table_id,\n    data_source,\n    variables,\n    x_position,\n    y_position,\n    height,\n    width,\n    add_totals_row=False,\n    table_title=None,\n    column_widths=None,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the background image to. If you used this package’s functions to create pages it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str chart_id: Please choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param str data_source: The name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard. :param list variables: The variables from the table that you want to include\n:param str table_title: Give your table an informative title!:D\n:param dict column_widths: Optional. Provide the width of columns. Provide the widths as a dictionary with column names as keys and widths as values. :param int x_position: The x coordinate of where you want to put the table on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the table on the page. Origin is page’s top left corner.\n:param int height: Height of table on the page :param int width: Width of table on the page\n:param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_table"
    ]
  },
  {
    "objectID": "reference/add_tmdl.html",
    "href": "reference/add_tmdl.html",
    "title": "add_tmdl",
    "section": "",
    "text": "add_tmdl\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_tmdl_dataset\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\nadd_tmdl.add_tmdl_dataset(\n    dashboard_path,\n    data_path=None,\n    add_default_datetable=True,\n)\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndata_path\nstr\nThe path where the tmdl file is stored.\nNone\n\n\nadd_default_datetable\nboolean\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence TMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset. In practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale Potential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\nTrue"
  },
  {
    "objectID": "reference/add_tmdl.html#functions",
    "href": "reference/add_tmdl.html#functions",
    "title": "add_tmdl",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_tmdl_dataset\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\nadd_tmdl.add_tmdl_dataset(\n    dashboard_path,\n    data_path=None,\n    add_default_datetable=True,\n)\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndata_path\nstr\nThe path where the tmdl file is stored.\nNone\n\n\nadd_default_datetable\nboolean\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence TMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset. In practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale Potential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\nTrue"
  },
  {
    "objectID": "reference/create_new_dashboard.html",
    "href": "reference/create_new_dashboard.html",
    "title": "create_new_dashboard",
    "section": "",
    "text": "create_new_dashboard\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_new_dashboard\nCreate a new dashboard in the specified folder\n\n\n\n\n\ncreate_new_dashboard.create_new_dashboard(parent_dir, report_name)\nCreate a new dashboard in the specified folder\n\nThis function creates a power BI report in the specified parent directory.\n\nThe dashboard can be opened and edited in Power BI desktop like normal, or be further modified progromatically using other functions in this package.\n\nThe function creates a folder with the name report_name inside parent_dir with all the dashboard’s files.\n\nThe dashboard uses a .pbip/.pbir format with TMDL enabled.\n\nTo publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing\n\nThese annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions.\n\n(.pbip uses mimified json by default and throws an error when it’s given unpacked json).\nThis dashboard turns off time intelligence and relationship autodection off by default\nIf you have the option I would recommend looking into a different web development framework (shiny, flask, etc) for building dashboards. Only use this package if you have to :D\n\n\n\nparent_dir: str\nThe path to the directory where you want to store the new dashboard\nreport_name: str\nName of the report.\n\n\n\nNone",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "create_new_dashboard"
    ]
  },
  {
    "objectID": "reference/create_new_dashboard.html#functions",
    "href": "reference/create_new_dashboard.html#functions",
    "title": "create_new_dashboard",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_new_dashboard\nCreate a new dashboard in the specified folder\n\n\n\n\n\ncreate_new_dashboard.create_new_dashboard(parent_dir, report_name)\nCreate a new dashboard in the specified folder\n\nThis function creates a power BI report in the specified parent directory.\n\nThe dashboard can be opened and edited in Power BI desktop like normal, or be further modified progromatically using other functions in this package.\n\nThe function creates a folder with the name report_name inside parent_dir with all the dashboard’s files.\n\nThe dashboard uses a .pbip/.pbir format with TMDL enabled.\n\nTo publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing\n\nThese annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions.\n\n(.pbip uses mimified json by default and throws an error when it’s given unpacked json).\nThis dashboard turns off time intelligence and relationship autodection off by default\nIf you have the option I would recommend looking into a different web development framework (shiny, flask, etc) for building dashboards. Only use this package if you have to :D\n\n\n\nparent_dir: str\nThe path to the directory where you want to store the new dashboard\nreport_name: str\nName of the report.\n\n\n\nNone",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "create_new_dashboard"
    ]
  },
  {
    "objectID": "reference/add_local_csv.html",
    "href": "reference/add_local_csv.html",
    "title": "add_local_csv",
    "section": "",
    "text": "add_local_csv\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_local_csv\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\nadd_local_csv.add_local_csv(dashboard_path, data_path, save_data_copy=True)\nAdd a locally stored CSV file to a dashboard\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str data_path: The path where the csv file is stored. Can be a relative path. The M code requires a full path, but this python function will help you resolve any valid relative paths to an absolute path.\n:param bool save_data_copy: Do you want to store a copy of the data in the dashboard’s project folder. This is important for some functions such as add_sanky_chart\n:returns: dataset_id: A randomly generated UUID that you can use to reference the datset.\nThe dataset path must be full (not relative path.) If using a relative path for the dashboard_path, the path must be within the current working directory. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_local_csv"
    ]
  },
  {
    "objectID": "reference/add_local_csv.html#functions",
    "href": "reference/add_local_csv.html#functions",
    "title": "add_local_csv",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_local_csv\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\nadd_local_csv.add_local_csv(dashboard_path, data_path, save_data_copy=True)\nAdd a locally stored CSV file to a dashboard\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str data_path: The path where the csv file is stored. Can be a relative path. The M code requires a full path, but this python function will help you resolve any valid relative paths to an absolute path.\n:param bool save_data_copy: Do you want to store a copy of the data in the dashboard’s project folder. This is important for some functions such as add_sanky_chart\n:returns: dataset_id: A randomly generated UUID that you can use to reference the datset.\nThe dataset path must be full (not relative path.) If using a relative path for the dashboard_path, the path must be within the current working directory. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_local_csv"
    ]
  },
  {
    "objectID": "example_dashboards.html",
    "href": "example_dashboards.html",
    "title": "Example Dashboards",
    "section": "",
    "text": "Here are some examples of Power BI dashboards built using {powerbpy}.\n\n\n\n\n\n\n\n\n\n\n\n\nRecreate my testing dasbhoard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSanky Chart and Table\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Power Bpy ",
    "section": "",
    "text": "Do you wish you could build dashboard with python or R, but can’t because the client specifically asked for Power BI or your employer only supports publishing Power BI? Do you love love love Power BI, but wish there was a way to automatically generate parts of your dashboard to speed up your development process?\nIntroducing Power Bpy, a python package that lets you create Power BI dashboards using functions 💪 instead of a point-and-click interface 🥹. Dashboards created using these functions can be opened, edited and saved normally in Power BI desktop.\nThis package uses the new .pbip/.pbir format with TMDL enabled. This stores dashboards as directories of text files instead of binary files letting you version control your dashboards! 🥳 These features are still preview features, so use this with caution until there’s more clarity from microsoft about what they’re going to do with .pbir and tmdl."
  },
  {
    "objectID": "index.html#dependencies",
    "href": "index.html#dependencies",
    "title": "Power Bpy ",
    "section": "Dependencies",
    "text": "Dependencies\nBefore you can start to build power BI dashboards using this package’s functions you’ll need the following:\n\n\n\nPython (version 3.12 or higher!) and pip installed and on path\n\n\nGit installed and on path\n\n\nPower BI Desktop (You can create the dashboards without this, but not view them).\n\n\nPower BI settings:\nYou’ll need to enable some preview features in Power BI Desktop. Navigate to File &gt; Options and Settings &gt; Options &gt; Preview features and enable the following options:\n\n\n\nShape map visual\n\n\nPower BI Project (.pbip) save option\n\n\nStore Semantic Model using TMDL format\n\n\nStore reports using enhanced metadata format (PBIR)"
  },
  {
    "objectID": "basic_setup.html",
    "href": "basic_setup.html",
    "title": "basic_setup",
    "section": "",
    "text": "Make sure python is installed on your computer.\n\n\n\n\nFor this example, we’re going to use a virtual environment to keep the package versions separate from what you have installed on your system 1. Open a command prompt and navigate to the folder you want to create dashboards in by running the following: shell    cd path/to/your/folder 2. Create and activate a virtual environment by running the same: ```shell # create a virtual environment python -m venv venv\n# for windows venv.bat\n# for linux or Mac (remove hashtag first) # source venv/bin/activate ```\n\nInstall the Power Bpy module:\n# install the Power Bpy module\npip install powerbpy\nWrite a script to create a dashboard. (This one’s up to you!)\nWhen you’re ready to create the dashboard, run the script by running the following in the command prompt window.\n\npython name_of_your_script.py\n\n\n\n\nInstall python\nYou’ll need to install python. Here are some instructions\n\nInstall Power Bpy\nThe {powerbpy} package isn’t on pypi yet, so you’ll need to install it from github. Open a terminal and enter the following:\n\npy -m pip install git+https://github.com/Russell-Shean/powerbpy.git#egg=powerbpy     \nAfter the package is on pypi, you’ll be able to install it using this:\npy -m pip install powerbpy\n\n\n\nThat’s all you need to install! To create the dashboards, you’ll need to either run the commands in a terminal, or use a text editor to save the commands in a a script. I recomend starting with a text editor, because as your dashboard grows more complex, it’ll be helpful to have everything saved in a script. Many text editors have an option to execute a script directly from the editor. You can also execute the scripts from the terminal using the following command:\npy build_dashboard.py\nThis assumes that you named your script build_dashboard.py and the command prompt’s current directory is the folder storing build_dashboard.py. You can change the current directory of the terminal using the cd command. For example you can use the following to move into C:/Users/:\ncd C:/Users/\nYou can also use full or relative paths from the current directory to the python script without changing the current working directory. For example if you start in your %userprofile% (C:/Users/[your username]) and the python script is stored at C:/Users/[your username]/python_projects/build_dashboard.py, you can execute the script with the following:\npy python_projects/build_dashboard.py"
  },
  {
    "objectID": "basic_setup.html#python",
    "href": "basic_setup.html#python",
    "title": "basic_setup",
    "section": "",
    "text": "Make sure python is installed on your computer."
  },
  {
    "objectID": "basic_setup.html#create-virtual-environment",
    "href": "basic_setup.html#create-virtual-environment",
    "title": "basic_setup",
    "section": "",
    "text": "For this example, we’re going to use a virtual environment to keep the package versions separate from what you have installed on your system 1. Open a command prompt and navigate to the folder you want to create dashboards in by running the following: shell    cd path/to/your/folder 2. Create and activate a virtual environment by running the same: ```shell # create a virtual environment python -m venv venv\n# for windows venv.bat\n# for linux or Mac (remove hashtag first) # source venv/bin/activate ```\n\nInstall the Power Bpy module:\n# install the Power Bpy module\npip install powerbpy\nWrite a script to create a dashboard. (This one’s up to you!)\nWhen you’re ready to create the dashboard, run the script by running the following in the command prompt window.\n\npython name_of_your_script.py"
  },
  {
    "objectID": "basic_setup.html#install-dependencies",
    "href": "basic_setup.html#install-dependencies",
    "title": "basic_setup",
    "section": "",
    "text": "Install python\nYou’ll need to install python. Here are some instructions\n\nInstall Power Bpy\nThe {powerbpy} package isn’t on pypi yet, so you’ll need to install it from github. Open a terminal and enter the following:\n\npy -m pip install git+https://github.com/Russell-Shean/powerbpy.git#egg=powerbpy     \nAfter the package is on pypi, you’ll be able to install it using this:\npy -m pip install powerbpy"
  },
  {
    "objectID": "basic_setup.html#executing-python-scripts",
    "href": "basic_setup.html#executing-python-scripts",
    "title": "basic_setup",
    "section": "",
    "text": "That’s all you need to install! To create the dashboards, you’ll need to either run the commands in a terminal, or use a text editor to save the commands in a a script. I recomend starting with a text editor, because as your dashboard grows more complex, it’ll be helpful to have everything saved in a script. Many text editors have an option to execute a script directly from the editor. You can also execute the scripts from the terminal using the following command:\npy build_dashboard.py\nThis assumes that you named your script build_dashboard.py and the command prompt’s current directory is the folder storing build_dashboard.py. You can change the current directory of the terminal using the cd command. For example you can use the following to move into C:/Users/:\ncd C:/Users/\nYou can also use full or relative paths from the current directory to the python script without changing the current working directory. For example if you start in your %userprofile% (C:/Users/[your username]) and the python script is stored at C:/Users/[your username]/python_projects/build_dashboard.py, you can execute the script with the following:\npy python_projects/build_dashboard.py"
  },
  {
    "objectID": "reference/add_background_image.html",
    "href": "reference/add_background_image.html",
    "title": "add_background_image",
    "section": "",
    "text": "add_background_image\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_background_image\nAdd a background image to a dashboard page\n\n\n\n\n\nadd_background_image.add_background_image(\n    dashboard_path,\n    page_id,\n    img_path,\n    alpha=100,\n    scaling_method='Fit',\n)\nAdd a background image to a dashboard page\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the chart to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str img_path: The path to the image you want to add. (Can be a relative path because the image is copied to the report folder). Allowed image types are whatever PBI allows manually, so probably at least jpeg and png :param int alpha: The transparency of the background image. Must be a whole integer between 1 and 100. :param str scaling_method: The method used to scale the image available options include [“Fit”, ]",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_background_image"
    ]
  },
  {
    "objectID": "reference/add_background_image.html#functions",
    "href": "reference/add_background_image.html#functions",
    "title": "add_background_image",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_background_image\nAdd a background image to a dashboard page\n\n\n\n\n\nadd_background_image.add_background_image(\n    dashboard_path,\n    page_id,\n    img_path,\n    alpha=100,\n    scaling_method='Fit',\n)\nAdd a background image to a dashboard page\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the chart to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str img_path: The path to the image you want to add. (Can be a relative path because the image is copied to the report folder). Allowed image types are whatever PBI allows manually, so probably at least jpeg and png :param int alpha: The transparency of the background image. Must be a whole integer between 1 and 100. :param str scaling_method: The method used to scale the image available options include [“Fit”, ]",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_background_image"
    ]
  },
  {
    "objectID": "reference/add_tmdl_dataset.html",
    "href": "reference/add_tmdl_dataset.html",
    "title": "add_tmdl_dataset",
    "section": "",
    "text": "add_tmdl_dataset\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_tmdl_dataset\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\nadd_tmdl_dataset.add_tmdl_dataset(\n    dashboard_path,\n    data_path=None,\n    add_default_datetable=True,\n)\nAdd a locally stored TMDL file to the dashboard\n\nTMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset.\n\nIn practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale\n\nPotential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\n\n\n\ndashboard_path: str\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\ndata_path: str\nThe path where the tmdl file is stored.\nadd_default_datetable: boolean\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_tmdl_dataset"
    ]
  },
  {
    "objectID": "reference/add_tmdl_dataset.html#functions",
    "href": "reference/add_tmdl_dataset.html#functions",
    "title": "add_tmdl_dataset",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_tmdl_dataset\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\nadd_tmdl_dataset.add_tmdl_dataset(\n    dashboard_path,\n    data_path=None,\n    add_default_datetable=True,\n)\nAdd a locally stored TMDL file to the dashboard\n\nTMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset.\n\nIn practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale\n\nPotential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\n\n\n\ndashboard_path: str\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\ndata_path: str\nThe path where the tmdl file is stored.\nadd_default_datetable: boolean\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_tmdl_dataset"
    ]
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Python functions for building Power BI dashboards\n\n\n\nadd_background_image\n\n\n\nadd_button\n\n\n\nadd_card\n\n\n\nadd_chart\n\n\n\nadd_csv_from_blob\n\n\n\nadd_local_csv\n\n\n\nadd_new_page\n\n\n\nadd_shape_map\n\n\n\nadd_slicer\n\n\n\nadd_sanky_chart\n\n\n\nadd_table\n\n\n\nadd_text_box\n\n\n\nadd_tmdl_dataset\n\n\n\ncreate_date_hrcy\n\n\n\ncreate_new_dashboard\n\n\n\ncreate_tmdl\n\n\n\ngenerate_bin_ranges\n\n\n\nget_measures_list\n\n\n\nupdate_diagramLayout\n\n\n\nupdate_model_file",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#power-bpy",
    "href": "reference/index.html#power-bpy",
    "title": "Function reference",
    "section": "",
    "text": "Python functions for building Power BI dashboards\n\n\n\nadd_background_image\n\n\n\nadd_button\n\n\n\nadd_card\n\n\n\nadd_chart\n\n\n\nadd_csv_from_blob\n\n\n\nadd_local_csv\n\n\n\nadd_new_page\n\n\n\nadd_shape_map\n\n\n\nadd_slicer\n\n\n\nadd_sanky_chart\n\n\n\nadd_table\n\n\n\nadd_text_box\n\n\n\nadd_tmdl_dataset\n\n\n\ncreate_date_hrcy\n\n\n\ncreate_new_dashboard\n\n\n\ncreate_tmdl\n\n\n\ngenerate_bin_ranges\n\n\n\nget_measures_list\n\n\n\nupdate_diagramLayout\n\n\n\nupdate_model_file",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/add_button.html",
    "href": "reference/add_button.html",
    "title": "add_button",
    "section": "",
    "text": "add_button\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_button\nAdd a button to a page\n\n\n\n\n\nadd_button.add_button(\n    label,\n    dashboard_path,\n    page_id,\n    button_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    fill_color='#3086C3',\n    alpha=0,\n    url_link=None,\n    page_navigation_link=None,\n)\nAdd a button to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlabel\nstr\nThe text you want to display inside the button\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\n\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nbutton_id\n\nPlease choose a unique id to use to identify the button. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nThis\n\n\nrequired",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_button"
    ]
  },
  {
    "objectID": "reference/add_button.html#functions",
    "href": "reference/add_button.html#functions",
    "title": "add_button",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_button\nAdd a button to a page\n\n\n\n\n\nadd_button.add_button(\n    label,\n    dashboard_path,\n    page_id,\n    button_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    fill_color='#3086C3',\n    alpha=0,\n    url_link=None,\n    page_navigation_link=None,\n)\nAdd a button to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlabel\nstr\nThe text you want to display inside the button\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\n\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nbutton_id\n\nPlease choose a unique id to use to identify the button. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nThis\n\n\nrequired",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_button"
    ]
  },
  {
    "objectID": "reference/update_diagramLayout.html",
    "href": "reference/update_diagramLayout.html",
    "title": "update_diagramLayout",
    "section": "",
    "text": "update_diagramLayout\n\n\n\n\n\nName\nDescription\n\n\n\n\nupdate_diagramLayout\nThis is an internal function to add a dataset to the diagramLayout file when a new dataset is added.\n\n\n\n\n\nupdate_diagramLayout.update_diagramLayout(\n    dashboard_path,\n    dataset_name,\n    dataset_id,\n)\nThis is an internal function to add a dataset to the diagramLayout file when a new dataset is added.\n:param str dashboard_path The path to the top level folder where you store all the report’s files. :param str dataset_name The name of the dataset you are adding :param str dataset_id The unique uuid that microsoft uses for the dataset. This is generated automatically within the add_data functions.\nreturn None",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "update_diagramLayout"
    ]
  },
  {
    "objectID": "reference/update_diagramLayout.html#functions",
    "href": "reference/update_diagramLayout.html#functions",
    "title": "update_diagramLayout",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nupdate_diagramLayout\nThis is an internal function to add a dataset to the diagramLayout file when a new dataset is added.\n\n\n\n\n\nupdate_diagramLayout.update_diagramLayout(\n    dashboard_path,\n    dataset_name,\n    dataset_id,\n)\nThis is an internal function to add a dataset to the diagramLayout file when a new dataset is added.\n:param str dashboard_path The path to the top level folder where you store all the report’s files. :param str dataset_name The name of the dataset you are adding :param str dataset_id The unique uuid that microsoft uses for the dataset. This is generated automatically within the add_data functions.\nreturn None",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "update_diagramLayout"
    ]
  },
  {
    "objectID": "reference/generate_bin_measures.html",
    "href": "reference/generate_bin_measures.html",
    "title": "generate_bin_measures",
    "section": "",
    "text": "generate_bin_measures\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_bin_measures\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\ngenerate_bin_measures.add_bin_measures(\n    dashboard_path,\n    dataset_name,\n    color_var,\n    percentile_bin_breaks,\n    color_palette,\n    filtering_var,\n    location_var,\n    data_filtering_condition=None,\n)\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndataset_name\nstr\nThe name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”.\nrequired\n\n\ndataset_id\nstr\nThe dataset’s UUID, this will be generated by the outer level function that calls create_tmdl().\nrequired\n\n\ndataset\nDataFrame\nThis is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\nrequired\n\n\ndata_filtering_condition\ndict\nThis is a key value pair for filtering long data. The key should be the column you want to look for and the value should be the value in that column that you want to filter for.For example if the original data has a column called metric with a variety of different metrics and you want to filter the dataset for only rows where the column is equal to “adj_rate”, you should provide the following {“metric”:“adj_rate”}\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ncol_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work. This function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions."
  },
  {
    "objectID": "reference/generate_bin_measures.html#functions",
    "href": "reference/generate_bin_measures.html#functions",
    "title": "generate_bin_measures",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_bin_measures\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\ngenerate_bin_measures.add_bin_measures(\n    dashboard_path,\n    dataset_name,\n    color_var,\n    percentile_bin_breaks,\n    color_palette,\n    filtering_var,\n    location_var,\n    data_filtering_condition=None,\n)\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndataset_name\nstr\nThe name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”.\nrequired\n\n\ndataset_id\nstr\nThe dataset’s UUID, this will be generated by the outer level function that calls create_tmdl().\nrequired\n\n\ndataset\nDataFrame\nThis is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\nrequired\n\n\ndata_filtering_condition\ndict\nThis is a key value pair for filtering long data. The key should be the column you want to look for and the value should be the value in that column that you want to filter for.For example if the original data has a column called metric with a variety of different metrics and you want to filter the dataset for only rows where the column is equal to “adj_rate”, you should provide the following {“metric”:“adj_rate”}\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ncol_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work. This function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions."
  },
  {
    "objectID": "reference/add_new_page.html",
    "href": "reference/add_new_page.html",
    "title": "add_new_page",
    "section": "",
    "text": "add_new_page\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_new_page\nCreate a new blank dashboard page\n\n\n\n\n\nadd_new_page.add_new_page(\n    dashboard_path,\n    page_name,\n    title=None,\n    subtitle=None,\n    displayOption='FitToPage',\n)\nCreate a new blank dashboard page\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_name: The display name for the page you just created. This is differnt from the page_id which is only used internally. :param str title: Title to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead. :param str sub_title: Title to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead. :param str displayOption: Default way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize\n:returns: new_page_id: The unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_new_page"
    ]
  },
  {
    "objectID": "reference/add_new_page.html#functions",
    "href": "reference/add_new_page.html#functions",
    "title": "add_new_page",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_new_page\nCreate a new blank dashboard page\n\n\n\n\n\nadd_new_page.add_new_page(\n    dashboard_path,\n    page_name,\n    title=None,\n    subtitle=None,\n    displayOption='FitToPage',\n)\nCreate a new blank dashboard page\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_name: The display name for the page you just created. This is differnt from the page_id which is only used internally. :param str title: Title to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead. :param str sub_title: Title to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead. :param str displayOption: Default way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize\n:returns: new_page_id: The unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_new_page"
    ]
  },
  {
    "objectID": "reference/update_model_file.html",
    "href": "reference/update_model_file.html",
    "title": "update_model_file",
    "section": "",
    "text": "update_model_file\n\n\n\n\n\nName\nDescription\n\n\n\n\nupdate_model_file\nThis is an internal function to add a dataset to the model.tmdl file when a new dataset is added.\n\n\n\n\n\nupdate_model_file.update_model_file(dashboard_path, dataset_name)\nThis is an internal function to add a dataset to the model.tmdl file when a new dataset is added. It assumes you want the new dataset to be loaded last.\n:param str dashboard_path The path to the top level folder where you store all the report’s files. :param str dataset_name The name of the dataset you are adding return None",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "update_model_file"
    ]
  },
  {
    "objectID": "reference/update_model_file.html#functions",
    "href": "reference/update_model_file.html#functions",
    "title": "update_model_file",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nupdate_model_file\nThis is an internal function to add a dataset to the model.tmdl file when a new dataset is added.\n\n\n\n\n\nupdate_model_file.update_model_file(dashboard_path, dataset_name)\nThis is an internal function to add a dataset to the model.tmdl file when a new dataset is added. It assumes you want the new dataset to be loaded last.\n:param str dashboard_path The path to the top level folder where you store all the report’s files. :param str dataset_name The name of the dataset you are adding return None",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "update_model_file"
    ]
  },
  {
    "objectID": "reference/add_slicer.html",
    "href": "reference/add_slicer.html",
    "title": "add_slicer",
    "section": "",
    "text": "add_slicer\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_slicer\nAdd a slicer to a page\n\n\n\n\n\nadd_slicer.add_slicer(\n    data_source,\n    column_name,\n    dashboard_path,\n    page_id,\n    slicer_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    title=None,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a slicer to a page\n:param str data_source: This is the name of the dataset that you want to use to populate the slicer with :param str column_name: This is the name of the measure (or variable) name you want to use to populate the slicer with :param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the slicer to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str slicer_id: Please choose a unique id to use to identify the slicer. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param int height: Height of slicer on the page :param int width: Width of slicer on the page\n:param int x_position: The x coordinate of where you want to put the slicer on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the slicer on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n:param str title: An optional title to add to the slicer. :param str text_align: How would you like the text aligned (available options: “left”, “right”, “center”) :param str font_weight: This is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”] :param int font_size: The font size in pts. Must be a whole integer. Defaults to 32 pt :param str font_color: Hex code for the font color you’d like to use. Defaults to black (#000000) :param str background_color: Hex code for the background color of the slicer. Defaults to None (transparent) :param str parent_group_id: This should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group.\nThis function creates a new slicer on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_slicer"
    ]
  },
  {
    "objectID": "reference/add_slicer.html#functions",
    "href": "reference/add_slicer.html#functions",
    "title": "add_slicer",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_slicer\nAdd a slicer to a page\n\n\n\n\n\nadd_slicer.add_slicer(\n    data_source,\n    column_name,\n    dashboard_path,\n    page_id,\n    slicer_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    title=None,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a slicer to a page\n:param str data_source: This is the name of the dataset that you want to use to populate the slicer with :param str column_name: This is the name of the measure (or variable) name you want to use to populate the slicer with :param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the slicer to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str slicer_id: Please choose a unique id to use to identify the slicer. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param int height: Height of slicer on the page :param int width: Width of slicer on the page\n:param int x_position: The x coordinate of where you want to put the slicer on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the slicer on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n:param str title: An optional title to add to the slicer. :param str text_align: How would you like the text aligned (available options: “left”, “right”, “center”) :param str font_weight: This is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”] :param int font_size: The font size in pts. Must be a whole integer. Defaults to 32 pt :param str font_color: Hex code for the font color you’d like to use. Defaults to black (#000000) :param str background_color: Hex code for the background color of the slicer. Defaults to None (transparent) :param str parent_group_id: This should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group.\nThis function creates a new slicer on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_slicer"
    ]
  },
  {
    "objectID": "reference/add_text_box.html",
    "href": "reference/add_text_box.html",
    "title": "add_text_box",
    "section": "",
    "text": "add_text_box\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_text_box\nAdd a text box to a page\n\n\n\n\n\nadd_text_box.add_text_box(\n    text,\n    dashboard_path,\n    page_id,\n    text_box_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a text box to a page\n:param str text: The text you want to display in the box :param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the text box to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str text_box_id: Please choose a unique id to use to identify the text box. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param int height: Height of text box on the page :param int width: Width of text box on the page\n:param int x_position: The x coordinate of where you want to put the text box on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the text box on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n:param str text_align: How would you like the text aligned (available options: “left”, “right”, “center”) :param str font_weight: This is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”] :param int font_size: The font size in pts. Must be a whole integer. Defaults to 32 pt :param str font_color: Hex code for the font color you’d like to use. Defaults to black (#000000) :param str background_color: Hex code for the background color of the text box. Defaults to None (transparent) :param str parent_group_id: This should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group.\nThis function creates a new text box on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_text_box"
    ]
  },
  {
    "objectID": "reference/add_text_box.html#functions",
    "href": "reference/add_text_box.html#functions",
    "title": "add_text_box",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_text_box\nAdd a text box to a page\n\n\n\n\n\nadd_text_box.add_text_box(\n    text,\n    dashboard_path,\n    page_id,\n    text_box_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a text box to a page\n:param str text: The text you want to display in the box :param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str page_id: The unique id for the page you want to add the text box to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list. :param str text_box_id: Please choose a unique id to use to identify the text box. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\n:param int height: Height of text box on the page :param int width: Width of text box on the page\n:param int x_position: The x coordinate of where you want to put the text box on the page. Origin is page’s top left corner. :param int y_position: The y coordinate of where you want to put the text box on the page. Origin is page’s top left corner. :param int z_position: The z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000 :param int tab_order: The order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n:param str text_align: How would you like the text aligned (available options: “left”, “right”, “center”) :param str font_weight: This is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”] :param int font_size: The font size in pts. Must be a whole integer. Defaults to 32 pt :param str font_color: Hex code for the font color you’d like to use. Defaults to black (#000000) :param str background_color: Hex code for the background color of the text box. Defaults to None (transparent) :param str parent_group_id: This should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group.\nThis function creates a new text box on a page.",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_text_box"
    ]
  },
  {
    "objectID": "reference/create_date_hrcy.html",
    "href": "reference/create_date_hrcy.html",
    "title": "create_date_hrcy",
    "section": "",
    "text": "create_date_hrcy\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_date_hrcy\n\n\n\n\n\n\ncreate_date_hrcy.create_date_hrcy(\n    col_name,\n    dataset_name,\n    report_name,\n    dashboard_path,\n)",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "create_date_hrcy"
    ]
  },
  {
    "objectID": "reference/create_date_hrcy.html#functions",
    "href": "reference/create_date_hrcy.html#functions",
    "title": "create_date_hrcy",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_date_hrcy\n\n\n\n\n\n\ncreate_date_hrcy.create_date_hrcy(\n    col_name,\n    dataset_name,\n    report_name,\n    dashboard_path,\n)",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "create_date_hrcy"
    ]
  },
  {
    "objectID": "reference/add_csv_from_blob.html",
    "href": "reference/add_csv_from_blob.html",
    "title": "add_csv_from_blob",
    "section": "",
    "text": "add_csv_from_blob\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_csv_from_blob\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\nadd_csv_from_blob.add_csv_from_blob(\n    dashboard_path,\n    account_url,\n    blob_name,\n    data_path,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    SAS_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\nDO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead.\nThis function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file. Thanks Microsoft for yet again doing a great job with backward compatibility lol. Dashboards created with the create_blank_dashboard() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str account_url: The url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field :param str blob_name: The name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field. :param str data_path: The relative path to the file you want to load from the blob. It should be relative to blob_name :param str tenant_id: The tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default). :param boolean use_saved_storage_key: This optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD. :param str SAS_url: A limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature” :param str storage_account_key: Please, Please, Please do not use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\n:returns: None",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_csv_from_blob"
    ]
  },
  {
    "objectID": "reference/add_csv_from_blob.html#functions",
    "href": "reference/add_csv_from_blob.html#functions",
    "title": "add_csv_from_blob",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_csv_from_blob\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\nadd_csv_from_blob.add_csv_from_blob(\n    dashboard_path,\n    account_url,\n    blob_name,\n    data_path,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    SAS_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\nDO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead.\nThis function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file. Thanks Microsoft for yet again doing a great job with backward compatibility lol. Dashboards created with the create_blank_dashboard() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this.\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str account_url: The url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field :param str blob_name: The name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field. :param str data_path: The relative path to the file you want to load from the blob. It should be relative to blob_name :param str tenant_id: The tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default). :param boolean use_saved_storage_key: This optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD. :param str SAS_url: A limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature” :param str storage_account_key: Please, Please, Please do not use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\n:returns: None",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "add_csv_from_blob"
    ]
  },
  {
    "objectID": "reference/get_measures_list.html",
    "href": "reference/get_measures_list.html",
    "title": "get_measures_list",
    "section": "",
    "text": "get_measures_list\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_measures_list\nReturns a list of DAX measures in the report\n\n\n\n\n\nget_measures_list.get_measures_list(\n    dashboard_path,\n    export_type='markdown',\n    output_file_path='',\n    starts_with='formatString:',\n)\nReturns a list of DAX measures in the report\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str export_type: Export type for the function result: export to a .xlsx file (parameter value ‘xlsx’), to a .csv file (parameter value ‘csv’), or output in markdown format without saving (parameter value ‘markdown’‘) :param str output_file_path: The path for export (if the export_type value is specified as’.xlsx’ or ‘.csv’). Example: “D:/PBI project/blank_template/”, export result will be stored as “D:/PBI project/blank_template/blank_template - measures.xlsx”” :param str starts_with: Technical parameter for measure selection. Default options is ‘formatString:’, for older reports without formatString in the measure definition try using ‘lineageTag:’ instead\n:returns: Returns a list of DAX measures used in the report in the specified format (see param export_type): the measure name, its definition, the table it belongs to, and the description (if available); prints “Measures not found” otherwise",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "get_measures_list"
    ]
  },
  {
    "objectID": "reference/get_measures_list.html#functions",
    "href": "reference/get_measures_list.html#functions",
    "title": "get_measures_list",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_measures_list\nReturns a list of DAX measures in the report\n\n\n\n\n\nget_measures_list.get_measures_list(\n    dashboard_path,\n    export_type='markdown',\n    output_file_path='',\n    starts_with='formatString:',\n)\nReturns a list of DAX measures in the report\n:param str dashboard_path: The path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders). :param str export_type: Export type for the function result: export to a .xlsx file (parameter value ‘xlsx’), to a .csv file (parameter value ‘csv’), or output in markdown format without saving (parameter value ‘markdown’‘) :param str output_file_path: The path for export (if the export_type value is specified as’.xlsx’ or ‘.csv’). Example: “D:/PBI project/blank_template/”, export result will be stored as “D:/PBI project/blank_template/blank_template - measures.xlsx”” :param str starts_with: Technical parameter for measure selection. Default options is ‘formatString:’, for older reports without formatString in the measure definition try using ‘lineageTag:’ instead\n:returns: Returns a list of DAX measures used in the report in the specified format (see param export_type): the measure name, its definition, the table it belongs to, and the description (if available); prints “Measures not found” otherwise",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "get_measures_list"
    ]
  },
  {
    "objectID": "example_dashboards/Test Dashboard/index.html",
    "href": "example_dashboards/Test Dashboard/index.html",
    "title": "Recreate my testing dasbhoard",
    "section": "",
    "text": "This example shows how I create the dashboard I use for testing the module. It isn’t pretty but it shows a good overview of everything that is currently possible to create using the module. You’ll learn how to:\n- create a new dashboard\n- add pages to the dashboard\n- add visual elements such as maps and charts to the pages"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/index.html#create-a-new-dashboard",
    "href": "example_dashboards/Test Dashboard/index.html#create-a-new-dashboard",
    "title": "Recreate my testing dasbhoard",
    "section": "Create a new dashboard",
    "text": "Create a new dashboard\nTo Create a new dashboard, you’ll need to provide two arguments:\n1. parent_dir - This is the folder where you want to store your dashboard\n2. report_name - This is the name you want to give your dashboard project.\nIf you want to create a dashboard called bigfoots in a folder called C:/Users/Russ/PBI_projects, here’s what the code should look like\n# Import the package\nimport powerbpy as PBI\n\n\nPBI.create_new_dashboard(report_location = \"C:/Users/Russ/PBI_projects\", report_name = \"bigfoots\")\n\n\n\n# Create a new dashboard -----------------------------------------------------------------------------------------\nPBI_dash.create_new_dashboard(report_location, report_name)    \nIf everything worked, the function should have created the following files:\n\nYou can open the bigfoots.pbip file in Power BI desktop normally. (Although you will probably need to turn on these preview features. )"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/index.html#add-a-new-page",
    "href": "example_dashboards/Test Dashboard/index.html#add-a-new-page",
    "title": "Recreate my testing dasbhoard",
    "section": "Add a new page",
    "text": "Add a new page"
  }
]
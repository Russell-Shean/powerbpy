[
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html",
    "href": "example_dashboards/Sanky Chart and Table/index.html",
    "title": "Sanky Chart and Table",
    "section": "",
    "text": "I used the PowerBpy python module to recreate an sanky chart and table dashboard from the Workout Wednesday Group challenge. Here’s a screenshot of the original dashboard (left) and the dashboard I recreated using Power Bpy (right). (It appears that the data has changed since the original author created his dashboard, so my version and his look a bit different because the data is a bit different, but the overall format is pretty similiar). The rest of the blog will describe key parts of the code I used to make the dashboard. The full code is available here.\n\n\nThis example assumes that you already have python installed and setup and that you know how to install python modules such as pandas.If you don’t, please refer to basic setup instructions on this page or find one of the many great resources online that explains how to install python packages.\nOne of the central assumptions built into the PowerBpy package is that you’d prefer to write python code over using Power BI. Therefore this example will avoid writing any M or DAX and will instead use python to extract, load and transform the data. Once the data is ready will use PowerBpy to create the dashboard.\n\n\n\nThe data for this example is stored as an online zip file. The following code downloads the zip file and extracts it into a local directory.\nimport requests\nimport py7zr\nimport os\nimport tempfile\n\n'''\nThis script downloads the data from Github and \nthen extracts the individual datasets from the compressed archive file. \n'''\n\n# step 1: obtain data from github --------------------------------------------------------------\n\n# Define paths\ndataset_url = \"https://github.com/sql-bi/Contoso-Data-Generator-V2-Data/releases/download/ready-to-use-data/csv-10k.7z\" \ndata_destination_dir = \"data\"\n\n\n# make sure the folder exists\nos.makedirs(data_destination_dir, exist_ok=True)\n\n# download the zip file from the internet\nresponse = requests.get(dataset_url, stream=True)\nresponse.raise_for_status()\n\n# write to file\nwith tempfile.NamedTemporaryFile(suffix=\".7z\", delete=False) as tmp_file:\n    with open(tmp_file.name, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n\n\n# extract the data \nwith py7zr.SevenZipFile(tmp_file.name, mode=\"r\") as z:\n    z.extractall(path=data_destination_dir)\n\n\n\n\nThe original example from WoW included creating measures in Power BI using DAX and M as part of the challenge. It’s also possible to create the needed variables in python and then upload the processed data to Power BI without writing any DAX or M.\nFor this example we need to calculate sales totals by stores time period and classify the sales as low, medium or high. Here’s the python code I used:\nimport pandas as pd\nimport numpy as np\n\n'''\nThis script proccess the data we downloaded \n'''\n\n# Read in the datasets\n# Assuming you used the download code above and didn't change the current directory,\n# the data should already be at this location\nstore = pd.read_csv(\"data/store.csv\")\nsales = pd.read_csv(\"data/sales.csv\")\n\n# Create a dictionary of names and codes\nstore_names = (\n                store[[\"StoreKey\", \"Description\"]]\n               .drop_duplicates()\n               .reset_index(drop=True)\n               )\n\n\n\n# Makes sure OrderDate is a date\nsales[\"OrderDate\"] = pd.to_datetime(sales[\"OrderDate\"])\n\n# Create a new dataframe with aggregate sales total\n# By date periods and store\nsales_by_store_and_date = (\n    sales\n\n    # assign seems to be similiar to mutate\n    .assign(\n\n        # np.select appears to be similiar to case_when\n        time_period = lambda df: np.select(\n\n\n            # Define to logical conditions to check for\n            [\n                df[\"OrderDate\"] &lt;= df\n                                   .groupby(\"StoreKey\")[\"OrderDate\"]\n                                   .transform(\"min\") \n                                   + pd.Timedelta(days=180),\n\n                df[\"OrderDate\"] &gt;= df\n                                   .groupby(\"StoreKey\")[\"OrderDate\"]\n                                   .transform(\"max\") \n                                   - pd.Timedelta(days=180)\n            ],\n\n            # Define labels if the conditions are met\n            [\"first_180\",\n             \"last_180\"],\n\n             # Define a default for if neither condition is matched\n             default=\"middle_period\"\n\n        )\n    ) \n\n    # calculate grouped sales totals by time period and store\n    .groupby([\"StoreKey\", \"time_period\"], as_index=False)\n    .agg(store_total_sales = (\"NetPrice\", \"sum\"))\n\n\n    # label the sales volumes as small, medium and large\n    .assign(\n\n        sales_size = lambda df: np.select(\n\n            [\n                df[\"store_total_sales\"] &lt; 1000,\n\n                (df[\"store_total_sales\"] &gt;= 1000) &\n                (df[\"store_total_sales\"] &lt; 5000),\n\n                df[\"store_total_sales\"] &gt;= 5000\n \n            ],\n\n            [ \n                \"Small\",\n                \"Medium\",\n                \"Large\"\n            ],\n        default=\"Unknown\" \n\n        ) \n\n    )\n\n    # Merge the store names onto the dataframe\n    .merge(  \n        store_names, \n        on = \"StoreKey\",\n        how = \"left\"\n    )\n\n    # pivot the dataframe to expand the time period and sales size columns wider\n    .pivot(\n        index=\"Description\",\n        columns=\"time_period\",\n        values=['store_total_sales', \"sales_size\"]\n    )\n\n)\n\n\n# undo the multi indexing of column names \n# (I don't even want to try to imagine how Power BI would try to handle that lol)\nsales_by_store_and_date.columns = [\n    f\"{val}_{col}\" for val, col in sales_by_store_and_date.columns\n]\n\n# finish the final steps in the chain\nsales_by_store_and_date = (\n\n    sales_by_store_and_date\n\n    # reset the index\n    .reset_index()\n\n    # select the columns we want\n    .loc[:, [\"Description\", \n             \"store_total_sales_first_180\",\n             \"store_total_sales_last_180\",\n             \"sales_size_first_180\",\n             \"sales_size_last_180\"]]\n\n    # Rename the columns we want\n    .rename(columns={\n        'Description': 'Name',\n        'store_total_sales_first_180': 'Sales First 180 Days',\n        'store_total_sales_last_180': 'Sales Last 180 Days',\n        'sales_size_first_180': 'Starting Size',\n        'sales_size_last_180': 'Ending Size'\n    })\n\n)\n\n# write to file\nsales_by_store_and_date.to_csv(\"data/final_dataset.csv\", index=False)   \nIt’s of course also possible to do this type of data processing in other languages too. Here’s a link to an R script I wrote that does the exact same data processing.\n\n\n\nNow that we’ve obtained and prepped the data, we can create the dashboard!\n\n\nFirst we create a new dashboard\nfrom powerbpy import Dashboard\nimport os\n\n# Define the path to the dashboard\ndashboard_path = os.path.join(os.getcwd(), \"sanky_demo\")\n\n# Create a new blank dashboard\nmy_dashboard = Dashboard.create(dashboard_path)\n\n\n\nNext we add the dataset we prepared to the dashboard\n# add the data from step 2\nmy_dashboard.add_local_csv(data_path = \"data/final_dataset.csv\" )\n\n\n\nNext we add a new page to the dashboard\n# Add a new page to the dashboard\npage1 = my_dashboard.new_page(page_name=\"A demonstration sanky chart\")\n\n\n\nNow that we have a dashboard, data and a page, we can start adding visuals. Here’s how to add a table:\n# add a table\npage1.add_table(visual_id = \"sales_table\", \n              data_source = \"final_dataset\", \n              variables = [\"Name\", \"Sales First 180 Days\", \"Sales Last 180 Days\", \"Starting Size\", \"Ending Size\"],\n              x_position = 615, \n              y_position = 0, \n              height = 800, \n              width = 615,\n              add_totals_row = False,\n              table_title = \"Store Sales Details\")\n\n\n\nNext we can add a sanky chart next to the table\npage1.add_sanky_chart(visual_id = \"sales_sanky\", \n              data_source = \"final_dataset\",\n              chart_title=\"Store Starting and Ending Size\",\n              starting_var=\"Starting Size\",\n              starting_var_values=[\"Large\", \"Medium\", \"Small\"], \n              ending_var=\"Ending Size\",\n              ending_var_values=[\"Large\", \"Medium\", \"Small\"],\n              values_from_var=\"Name\", \n              x_position=0, \n              y_position=0, \n              height = 800, \n              width = 615)\nHere’s a link to the dashboard creation script.\nAnd heres a link to the script for the entire process including data processing."
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#assumptions",
    "href": "example_dashboards/Sanky Chart and Table/index.html#assumptions",
    "title": "Sanky Chart and Table",
    "section": "",
    "text": "This example assumes that you already have python installed and setup and that you know how to install python modules such as pandas.If you don’t, please refer to basic setup instructions on this page or find one of the many great resources online that explains how to install python packages.\nOne of the central assumptions built into the PowerBpy package is that you’d prefer to write python code over using Power BI. Therefore this example will avoid writing any M or DAX and will instead use python to extract, load and transform the data. Once the data is ready will use PowerBpy to create the dashboard."
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#download-data",
    "href": "example_dashboards/Sanky Chart and Table/index.html#download-data",
    "title": "Sanky Chart and Table",
    "section": "",
    "text": "The data for this example is stored as an online zip file. The following code downloads the zip file and extracts it into a local directory.\nimport requests\nimport py7zr\nimport os\nimport tempfile\n\n'''\nThis script downloads the data from Github and \nthen extracts the individual datasets from the compressed archive file. \n'''\n\n# step 1: obtain data from github --------------------------------------------------------------\n\n# Define paths\ndataset_url = \"https://github.com/sql-bi/Contoso-Data-Generator-V2-Data/releases/download/ready-to-use-data/csv-10k.7z\" \ndata_destination_dir = \"data\"\n\n\n# make sure the folder exists\nos.makedirs(data_destination_dir, exist_ok=True)\n\n# download the zip file from the internet\nresponse = requests.get(dataset_url, stream=True)\nresponse.raise_for_status()\n\n# write to file\nwith tempfile.NamedTemporaryFile(suffix=\".7z\", delete=False) as tmp_file:\n    with open(tmp_file.name, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n\n\n# extract the data \nwith py7zr.SevenZipFile(tmp_file.name, mode=\"r\") as z:\n    z.extractall(path=data_destination_dir)"
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#process-data",
    "href": "example_dashboards/Sanky Chart and Table/index.html#process-data",
    "title": "Sanky Chart and Table",
    "section": "",
    "text": "The original example from WoW included creating measures in Power BI using DAX and M as part of the challenge. It’s also possible to create the needed variables in python and then upload the processed data to Power BI without writing any DAX or M.\nFor this example we need to calculate sales totals by stores time period and classify the sales as low, medium or high. Here’s the python code I used:\nimport pandas as pd\nimport numpy as np\n\n'''\nThis script proccess the data we downloaded \n'''\n\n# Read in the datasets\n# Assuming you used the download code above and didn't change the current directory,\n# the data should already be at this location\nstore = pd.read_csv(\"data/store.csv\")\nsales = pd.read_csv(\"data/sales.csv\")\n\n# Create a dictionary of names and codes\nstore_names = (\n                store[[\"StoreKey\", \"Description\"]]\n               .drop_duplicates()\n               .reset_index(drop=True)\n               )\n\n\n\n# Makes sure OrderDate is a date\nsales[\"OrderDate\"] = pd.to_datetime(sales[\"OrderDate\"])\n\n# Create a new dataframe with aggregate sales total\n# By date periods and store\nsales_by_store_and_date = (\n    sales\n\n    # assign seems to be similiar to mutate\n    .assign(\n\n        # np.select appears to be similiar to case_when\n        time_period = lambda df: np.select(\n\n\n            # Define to logical conditions to check for\n            [\n                df[\"OrderDate\"] &lt;= df\n                                   .groupby(\"StoreKey\")[\"OrderDate\"]\n                                   .transform(\"min\") \n                                   + pd.Timedelta(days=180),\n\n                df[\"OrderDate\"] &gt;= df\n                                   .groupby(\"StoreKey\")[\"OrderDate\"]\n                                   .transform(\"max\") \n                                   - pd.Timedelta(days=180)\n            ],\n\n            # Define labels if the conditions are met\n            [\"first_180\",\n             \"last_180\"],\n\n             # Define a default for if neither condition is matched\n             default=\"middle_period\"\n\n        )\n    ) \n\n    # calculate grouped sales totals by time period and store\n    .groupby([\"StoreKey\", \"time_period\"], as_index=False)\n    .agg(store_total_sales = (\"NetPrice\", \"sum\"))\n\n\n    # label the sales volumes as small, medium and large\n    .assign(\n\n        sales_size = lambda df: np.select(\n\n            [\n                df[\"store_total_sales\"] &lt; 1000,\n\n                (df[\"store_total_sales\"] &gt;= 1000) &\n                (df[\"store_total_sales\"] &lt; 5000),\n\n                df[\"store_total_sales\"] &gt;= 5000\n \n            ],\n\n            [ \n                \"Small\",\n                \"Medium\",\n                \"Large\"\n            ],\n        default=\"Unknown\" \n\n        ) \n\n    )\n\n    # Merge the store names onto the dataframe\n    .merge(  \n        store_names, \n        on = \"StoreKey\",\n        how = \"left\"\n    )\n\n    # pivot the dataframe to expand the time period and sales size columns wider\n    .pivot(\n        index=\"Description\",\n        columns=\"time_period\",\n        values=['store_total_sales', \"sales_size\"]\n    )\n\n)\n\n\n# undo the multi indexing of column names \n# (I don't even want to try to imagine how Power BI would try to handle that lol)\nsales_by_store_and_date.columns = [\n    f\"{val}_{col}\" for val, col in sales_by_store_and_date.columns\n]\n\n# finish the final steps in the chain\nsales_by_store_and_date = (\n\n    sales_by_store_and_date\n\n    # reset the index\n    .reset_index()\n\n    # select the columns we want\n    .loc[:, [\"Description\", \n             \"store_total_sales_first_180\",\n             \"store_total_sales_last_180\",\n             \"sales_size_first_180\",\n             \"sales_size_last_180\"]]\n\n    # Rename the columns we want\n    .rename(columns={\n        'Description': 'Name',\n        'store_total_sales_first_180': 'Sales First 180 Days',\n        'store_total_sales_last_180': 'Sales Last 180 Days',\n        'sales_size_first_180': 'Starting Size',\n        'sales_size_last_180': 'Ending Size'\n    })\n\n)\n\n# write to file\nsales_by_store_and_date.to_csv(\"data/final_dataset.csv\", index=False)   \nIt’s of course also possible to do this type of data processing in other languages too. Here’s a link to an R script I wrote that does the exact same data processing."
  },
  {
    "objectID": "example_dashboards/Sanky Chart and Table/index.html#create-dashboard",
    "href": "example_dashboards/Sanky Chart and Table/index.html#create-dashboard",
    "title": "Sanky Chart and Table",
    "section": "",
    "text": "Now that we’ve obtained and prepped the data, we can create the dashboard!\n\n\nFirst we create a new dashboard\nfrom powerbpy import Dashboard\nimport os\n\n# Define the path to the dashboard\ndashboard_path = os.path.join(os.getcwd(), \"sanky_demo\")\n\n# Create a new blank dashboard\nmy_dashboard = Dashboard.create(dashboard_path)\n\n\n\nNext we add the dataset we prepared to the dashboard\n# add the data from step 2\nmy_dashboard.add_local_csv(data_path = \"data/final_dataset.csv\" )\n\n\n\nNext we add a new page to the dashboard\n# Add a new page to the dashboard\npage1 = my_dashboard.new_page(page_name=\"A demonstration sanky chart\")\n\n\n\nNow that we have a dashboard, data and a page, we can start adding visuals. Here’s how to add a table:\n# add a table\npage1.add_table(visual_id = \"sales_table\", \n              data_source = \"final_dataset\", \n              variables = [\"Name\", \"Sales First 180 Days\", \"Sales Last 180 Days\", \"Starting Size\", \"Ending Size\"],\n              x_position = 615, \n              y_position = 0, \n              height = 800, \n              width = 615,\n              add_totals_row = False,\n              table_title = \"Store Sales Details\")\n\n\n\nNext we can add a sanky chart next to the table\npage1.add_sanky_chart(visual_id = \"sales_sanky\", \n              data_source = \"final_dataset\",\n              chart_title=\"Store Starting and Ending Size\",\n              starting_var=\"Starting Size\",\n              starting_var_values=[\"Large\", \"Medium\", \"Small\"], \n              ending_var=\"Ending Size\",\n              ending_var_values=[\"Large\", \"Medium\", \"Small\"],\n              values_from_var=\"Name\", \n              x_position=0, \n              y_position=0, \n              height = 800, \n              width = 615)\nHere’s a link to the dashboard creation script.\nAnd heres a link to the script for the entire process including data processing."
  },
  {
    "objectID": "reference/add_ADLS_csv.html",
    "href": "reference/add_ADLS_csv.html",
    "title": "add_ADLS_csv",
    "section": "",
    "text": "add_ADLS_csv\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_csv_from_blob\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\nadd_ADLS_csv.add_csv_from_blob(\n    dashboard_path,\n    account_url,\n    blob_name,\n    data_path,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    SAS_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\naccount_url\nstr\nThe url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field\nrequired\n\n\nblob_name\nstr\nThe name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field.\nrequired\n\n\ndata_path\nstr\nThe relative path to the file you want to load from the blob. It should be relative to blob_name\nrequired\n\n\ntenant_id\nstr\nThe tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default).\nNone\n\n\nuse_saved_storage_key\nboolean\nThis optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD.\nFalse\n\n\nSAS_url\nstr\nA limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature”\nNone\n\n\nstorage_account_key\nstr\nPlease, Please, Please do not use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nNone DO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function. This function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file. Thanks Microsoft for yet again doing a great job with backward compatibility lol. Dashboards created with the create_blank_dashboard() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this."
  },
  {
    "objectID": "reference/add_ADLS_csv.html#functions",
    "href": "reference/add_ADLS_csv.html#functions",
    "title": "add_ADLS_csv",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_csv_from_blob\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\nadd_ADLS_csv.add_csv_from_blob(\n    dashboard_path,\n    account_url,\n    blob_name,\n    data_path,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    SAS_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\naccount_url\nstr\nThe url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field\nrequired\n\n\nblob_name\nstr\nThe name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field.\nrequired\n\n\ndata_path\nstr\nThe relative path to the file you want to load from the blob. It should be relative to blob_name\nrequired\n\n\ntenant_id\nstr\nThe tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default).\nNone\n\n\nuse_saved_storage_key\nboolean\nThis optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD.\nFalse\n\n\nSAS_url\nstr\nA limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature”\nNone\n\n\nstorage_account_key\nstr\nPlease, Please, Please do not use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nNone DO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function. This function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file. Thanks Microsoft for yet again doing a great job with backward compatibility lol. Dashboards created with the create_blank_dashboard() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this."
  },
  {
    "objectID": "reference/add_card.html",
    "href": "reference/add_card.html",
    "title": "add_card",
    "section": "",
    "text": "add_card(\n    data_source,\n    measure_name,\n    dashboard_path,\n    page_id,\n    card_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    title=None,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a card to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_source\nstr\nThis is the name of the dataset that you want to use to populate the card with\nrequired\n\n\nmeasure_name\nstr\nThis is the name of the measure (or variable) name you want to use to populate the card with\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the card to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\ncard_id\nstr\nPlease choose a unique id to use to identify the card. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of card on the page\nrequired\n\n\nwidth\nint\nWidth of card on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the card on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the card on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\ntitle\nstr\nAn optional title to add to the card.\nNone\n\n\ntext_align\nstr\nHow would you like the text aligned (available options: “left”, “right”, “center”)\n'left'\n\n\nfont_weight\nstr\nThis is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”]\n'bold'\n\n\nfont_size\nint\nThe font size in pts. Must be a whole integer. Defaults to 32 pt\n32\n\n\nfont_color\nstr\nHex code for the font color you’d like to use. Defaults to black (#000000)\n'#000000'\n\n\nbackground_color\nstr\nHex code for the background color of the card. Defaults to None (transparent)\nNone\n\n\nparent_group_id\nstr\nThis should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group. This function creates a new card on a page.\nNone"
  },
  {
    "objectID": "reference/add_card.html#parameters",
    "href": "reference/add_card.html#parameters",
    "title": "add_card",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata_source\nstr\nThis is the name of the dataset that you want to use to populate the card with\nrequired\n\n\nmeasure_name\nstr\nThis is the name of the measure (or variable) name you want to use to populate the card with\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the card to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\ncard_id\nstr\nPlease choose a unique id to use to identify the card. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of card on the page\nrequired\n\n\nwidth\nint\nWidth of card on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the card on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the card on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\ntitle\nstr\nAn optional title to add to the card.\nNone\n\n\ntext_align\nstr\nHow would you like the text aligned (available options: “left”, “right”, “center”)\n'left'\n\n\nfont_weight\nstr\nThis is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”]\n'bold'\n\n\nfont_size\nint\nThe font size in pts. Must be a whole integer. Defaults to 32 pt\n32\n\n\nfont_color\nstr\nHex code for the font color you’d like to use. Defaults to black (#000000)\n'#000000'\n\n\nbackground_color\nstr\nHex code for the background color of the card. Defaults to None (transparent)\nNone\n\n\nparent_group_id\nstr\nThis should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group. This function creates a new card on a page.\nNone"
  },
  {
    "objectID": "reference/add_text_box.html",
    "href": "reference/add_text_box.html",
    "title": "add_text_box",
    "section": "",
    "text": "add_text_box(\n    text,\n    dashboard_path,\n    page_id,\n    text_box_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a text box to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntext\nstr\nThe text you want to display in the box\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the text box to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\ntext_box_id\nstr\nPlease choose a unique id to use to identify the text box. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of text box on the page\nrequired\n\n\nwidth\nint\nWidth of text box on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\ntext_align\nstr\nHow would you like the text aligned (available options: “left”, “right”, “center”)\n'left'\n\n\nfont_weight\nstr\nThis is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”]\n'bold'\n\n\nfont_size\nint\nThe font size in pts. Must be a whole integer. Defaults to 32 pt\n32\n\n\nfont_color\nstr\nHex code for the font color you’d like to use. Defaults to black (#000000)\n'#000000'\n\n\nbackground_color\nstr\nHex code for the background color of the text box. Defaults to None (transparent)\nNone\n\n\nparent_group_id\nstr\nThis should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group. This function creates a new text box on a page.\nNone"
  },
  {
    "objectID": "reference/add_text_box.html#parameters",
    "href": "reference/add_text_box.html#parameters",
    "title": "add_text_box",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ntext\nstr\nThe text you want to display in the box\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the text box to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\ntext_box_id\nstr\nPlease choose a unique id to use to identify the text box. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of text box on the page\nrequired\n\n\nwidth\nint\nWidth of text box on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\ntext_align\nstr\nHow would you like the text aligned (available options: “left”, “right”, “center”)\n'left'\n\n\nfont_weight\nstr\nThis is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”]\n'bold'\n\n\nfont_size\nint\nThe font size in pts. Must be a whole integer. Defaults to 32 pt\n32\n\n\nfont_color\nstr\nHex code for the font color you’d like to use. Defaults to black (#000000)\n'#000000'\n\n\nbackground_color\nstr\nHex code for the background color of the text box. Defaults to None (transparent)\nNone\n\n\nparent_group_id\nstr\nThis should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group. This function creates a new text box on a page.\nNone"
  },
  {
    "objectID": "reference/page.html",
    "href": "reference/page.html",
    "title": "page",
    "section": "",
    "text": "page\npage",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "page"
    ]
  },
  {
    "objectID": "reference/update_model_file.html",
    "href": "reference/update_model_file.html",
    "title": "update_model_file",
    "section": "",
    "text": "update_model_file\nupdate_model_file(dashboard_path, dataset_name)\nThis is an internal function to add a dataset to the model.tmdl file when a new dataset is added. It assumes you want the new dataset to be loaded last."
  },
  {
    "objectID": "reference/create_blank_dashboard.html",
    "href": "reference/create_blank_dashboard.html",
    "title": "create_blank_dashboard",
    "section": "",
    "text": "create_blank_dashboard\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_new_dashboard\nCreate a new dashboard in the specified folder\n\n\n\n\n\ncreate_blank_dashboard.create_new_dashboard(parent_dir, report_name)\nCreate a new dashboard in the specified folder\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nparent_dir\nstr\nThe path to the directory where you want to store the new dashboard\nrequired\n\n\nreport_name\nstr\nName of the report. This function creates a power BI report in the specified parent directory. The dashboard can be opened and edited in Power BI desktop like normal, or be further modified progromatically using other functions in this package. The function creates a folder with the name report_name inside parent_dir with all the dashboard’s files. The dashboard uses a .pbip/.pbir format with TMDL enabled. To publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing These annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions. (.pbip uses mimified json by default and throws an error when it’s given unpacked json). This dashboard turns off time intelligence and relationship autodection off by default If you have the option I would recommend looking into a different web development framework (shiny, flask, etc) for building dashboards. Only use this package if you have to :D\nrequired"
  },
  {
    "objectID": "reference/create_blank_dashboard.html#functions",
    "href": "reference/create_blank_dashboard.html#functions",
    "title": "create_blank_dashboard",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_new_dashboard\nCreate a new dashboard in the specified folder\n\n\n\n\n\ncreate_blank_dashboard.create_new_dashboard(parent_dir, report_name)\nCreate a new dashboard in the specified folder\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nparent_dir\nstr\nThe path to the directory where you want to store the new dashboard\nrequired\n\n\nreport_name\nstr\nName of the report. This function creates a power BI report in the specified parent directory. The dashboard can be opened and edited in Power BI desktop like normal, or be further modified progromatically using other functions in this package. The function creates a folder with the name report_name inside parent_dir with all the dashboard’s files. The dashboard uses a .pbip/.pbir format with TMDL enabled. To publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing These annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions. (.pbip uses mimified json by default and throws an error when it’s given unpacked json). This dashboard turns off time intelligence and relationship autodection off by default If you have the option I would recommend looking into a different web development framework (shiny, flask, etc) for building dashboards. Only use this package if you have to :D\nrequired"
  },
  {
    "objectID": "reference/create_new_chart.html",
    "href": "reference/create_new_chart.html",
    "title": "create_new_chart",
    "section": "",
    "text": "create_new_chart\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\ncreate_new_chart.add_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    chart_type,\n    data_source,\n    chart_title,\n    x_axis_title,\n    y_axis_title,\n    x_axis_var,\n    y_axis_var,\n    y_axis_var_aggregation_type,\n    x_position,\n    y_position,\n    height,\n    width,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nchart_id\nstr\nPlease choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nchart_type\nstr\nThe type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ]\nrequired\n\n\ndata_source\nstr\nThe name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\nrequired\n\n\nchart_title\nstr\nGive your chart an informative title!:D\nrequired\n\n\nx_axis_title\nstr\nText to display on the x axis\nrequired\n\n\ny_axis_title\nstr\nText to display on the y axis\nrequired\n\n\nx_axis_var\nstr\nColumn name of a column from data_source that you want to use for the x axis of the chart\nrequired\n\n\ny_axis_var\nstr\nColumn name of a column from data_source that you want to use for the y axis of the chart\nrequired\n\n\ny_axis_var_aggregation_type\nstr\nType of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\nheight\nint\nHeight of chart on the page\nrequired\n\n\nwidth\nint\nWidth of chart on the page\nrequired\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000"
  },
  {
    "objectID": "reference/create_new_chart.html#functions",
    "href": "reference/create_new_chart.html#functions",
    "title": "create_new_chart",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_chart\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\ncreate_new_chart.add_chart(\n    dashboard_path,\n    page_id,\n    chart_id,\n    chart_type,\n    data_source,\n    chart_title,\n    x_axis_title,\n    y_axis_title,\n    x_axis_var,\n    y_axis_var,\n    y_axis_var_aggregation_type,\n    x_position,\n    y_position,\n    height,\n    width,\n    tab_order=-1001,\n    z_position=6000,\n)\nThis function adds a new chart to a page in a power BI dashboard report.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nchart_id\nstr\nPlease choose a unique id to use to identify the chart. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nchart_type\nstr\nThe type of chart to build on the page. Known available types include: [“columnChart”,“barChart”, “clusteredBarChart”, ]\nrequired\n\n\ndata_source\nstr\nThe name of the dataset you want to use to build the chart. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\nrequired\n\n\nchart_title\nstr\nGive your chart an informative title!:D\nrequired\n\n\nx_axis_title\nstr\nText to display on the x axis\nrequired\n\n\ny_axis_title\nstr\nText to display on the y axis\nrequired\n\n\nx_axis_var\nstr\nColumn name of a column from data_source that you want to use for the x axis of the chart\nrequired\n\n\ny_axis_var\nstr\nColumn name of a column from data_source that you want to use for the y axis of the chart\nrequired\n\n\ny_axis_var_aggregation_type\nstr\nType of aggregation method you want to use to summarize y axis variable. Available options include” [“Sum”, “Count”, “Average”]\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\nrequired\n\n\nheight\nint\nHeight of chart on the page\nrequired\n\n\nwidth\nint\nWidth of chart on the page\nrequired\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000"
  },
  {
    "objectID": "reference/add_button.html",
    "href": "reference/add_button.html",
    "title": "add_button",
    "section": "",
    "text": "add_button(\n    label,\n    dashboard_path,\n    page_id,\n    button_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    fill_color='#3086C3',\n    alpha=0,\n    url_link=None,\n    page_navigation_link=None,\n)\nAdd a text box to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlabel\nstr\nThe text you want to display inside the button.\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nbutton_id\nstr\nPlease choose a unique id to use to identify the button. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of text box on the page\nrequired\n\n\nwidth\nint\nWidth of text box on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\nfill_color\nint\nHex code for the background (fill) color you’d like to use for the button. Defaults to blue (#3086C3)\n'#3086C3'\n\n\nalpha\nint\nThe transparency of the background image. Must be a whole integer between 1 and 100. Defaults to 0 (100% not transparent)\n0\n\n\nurl_link\nstr\nOptional argument. If provided, the button will navigate to this URL. Should be a full, not relative url\nNone\n\n\npage_navigation_link\nstr\nOptional argument. If provided the button will navigate to this page in the report. Must be a valid page_id already present in the report. This function creates a new button on a page.\nNone"
  },
  {
    "objectID": "reference/add_button.html#parameters",
    "href": "reference/add_button.html#parameters",
    "title": "add_button",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nlabel\nstr\nThe text you want to display inside the button.\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the background image to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nbutton_id\nstr\nPlease choose a unique id to use to identify the button. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of text box on the page\nrequired\n\n\nwidth\nint\nWidth of text box on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the text box on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\nfill_color\nint\nHex code for the background (fill) color you’d like to use for the button. Defaults to blue (#3086C3)\n'#3086C3'\n\n\nalpha\nint\nThe transparency of the background image. Must be a whole integer between 1 and 100. Defaults to 0 (100% not transparent)\n0\n\n\nurl_link\nstr\nOptional argument. If provided, the button will navigate to this URL. Should be a full, not relative url\nNone\n\n\npage_navigation_link\nstr\nOptional argument. If provided the button will navigate to this page in the report. Must be a valid page_id already present in the report. This function creates a new button on a page.\nNone"
  },
  {
    "objectID": "reference/add_tmdl.html",
    "href": "reference/add_tmdl.html",
    "title": "add_tmdl",
    "section": "",
    "text": "add_tmdl\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_tmdl_dataset\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\nadd_tmdl.add_tmdl_dataset(\n    dashboard_path,\n    data_path=None,\n    add_default_datetable=True,\n)\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndata_path\nstr\nThe path where the tmdl file is stored.\nNone\n\n\nadd_default_datetable\nboolean\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence TMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset. In practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale Potential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\nTrue"
  },
  {
    "objectID": "reference/add_tmdl.html#functions",
    "href": "reference/add_tmdl.html#functions",
    "title": "add_tmdl",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_tmdl_dataset\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\nadd_tmdl.add_tmdl_dataset(\n    dashboard_path,\n    data_path=None,\n    add_default_datetable=True,\n)\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndata_path\nstr\nThe path where the tmdl file is stored.\nNone\n\n\nadd_default_datetable\nboolean\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence TMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset. In practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale Potential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\nTrue"
  },
  {
    "objectID": "reference/add_local_csv.html",
    "href": "reference/add_local_csv.html",
    "title": "add_local_csv",
    "section": "",
    "text": "add_local_csv\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_csv\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\nadd_local_csv.add_csv(dashboard_path, data_path)\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndata_path\nstr\nThe path where the csv file is stored. MUST BE A FULL PATH FOR THE M CODE TO WORK.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ndataset_id: A randomly generated UUID that you can use to reference the datset. The dataset path must be full (not relative path.) If using a relative path for the dashboard_path, the path must be within the current working directory. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function. This function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset."
  },
  {
    "objectID": "reference/add_local_csv.html#functions",
    "href": "reference/add_local_csv.html#functions",
    "title": "add_local_csv",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_csv\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\nadd_local_csv.add_csv(dashboard_path, data_path)\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndata_path\nstr\nThe path where the csv file is stored. MUST BE A FULL PATH FOR THE M CODE TO WORK.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ndataset_id: A randomly generated UUID that you can use to reference the datset. The dataset path must be full (not relative path.) If using a relative path for the dashboard_path, the path must be within the current working directory. This function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function. This function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset."
  },
  {
    "objectID": "example_dashboards.html",
    "href": "example_dashboards.html",
    "title": "Example Dashboards",
    "section": "",
    "text": "Here are some examples of Power BI dashboards built using {powerbpy}.\n\n\n\n\n\n\n\n\n\n\n\n\nRecreate my testing dashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSanky Chart and Table\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Power Bpy ",
    "section": "",
    "text": "Do you wish you could build dashboard with python or R, but can’t because the client specifically asked for Power BI or your employer only supports publishing Power BI? Do you love love love Power BI, but wish there was a way to automatically generate parts of your dashboard to speed up your development process?\nIntroducing Power Bpy, a python package that lets you create Power BI dashboards using functions 💪 instead of a point-and-click interface 🥹. Dashboards created using these functions can be opened, edited and saved normally in Power BI desktop.\nThis package uses the new .pbip/.pbir format with TMDL enabled. This stores dashboards as directories of text files instead of binary files letting you version control your dashboards! 🥳 These features are still preview features, so use this with caution until there’s more clarity from microsoft about what they’re going to do with .pbir and tmdl."
  },
  {
    "objectID": "index.html#dependencies",
    "href": "index.html#dependencies",
    "title": "Power Bpy ",
    "section": "Dependencies",
    "text": "Dependencies\nBefore you can start to build power BI dashboards using this package’s functions you’ll need the following:\n\n\n\nPython (version 3.12 or higher!) and pip installed and on path\n\n\nGit installed and on path\n\n\nPower BI Desktop (You can create the dashboards without this, but not view them).\n\n\nPower BI settings:\nYou’ll need to enable some preview features in Power BI Desktop. Navigate to File &gt; Options and Settings &gt; Options &gt; Preview features and enable the following options:\n\n\n\nShape map visual\n\n\nPower BI Project (.pbip) save option\n\n\nStore Semantic Model using TMDL format\n\n\nStore reports using enhanced metadata format (PBIR)"
  },
  {
    "objectID": "basic_setup.html",
    "href": "basic_setup.html",
    "title": "basic_setup",
    "section": "",
    "text": "Make sure python is installed on your computer.\n\n\n\n\nFor this example, we’re going to use a virtual environment to keep the package versions separate from what you have installed on your system 1. Open a command prompt and navigate to the folder you want to create dashboards in by running the following: shell    cd path/to/your/folder 2. Create and activate a virtual environment by running the same: ```shell # create a virtual environment python -m venv venv\n# for windows venv.bat\n# for linux or Mac (remove hashtag first) # source venv/bin/activate ```\n\nInstall the Power Bpy module:\n# install the Power Bpy module\npip install powerbpy\nWrite a script to create a dashboard. (This one’s up to you!)\nWhen you’re ready to create the dashboard, run the script by running the following in the command prompt window.\n\npython name_of_your_script.py\n\n\n\n\nInstall python\nYou’ll need to install python. Here are some instructions\n\nInstall Power Bpy\nThe {powerbpy} package isn’t on pypi yet, so you’ll need to install it from github. Open a terminal and enter the following:\n\npy -m pip install git+https://github.com/Russell-Shean/powerbpy.git#egg=powerbpy     \nAfter the package is on pypi, you’ll be able to install it using this:\npy -m pip install powerbpy\n\n\n\nThat’s all you need to install! To create the dashboards, you’ll need to either run the commands in a terminal, or use a text editor to save the commands in a a script. I recomend starting with a text editor, because as your dashboard grows more complex, it’ll be helpful to have everything saved in a script. Many text editors have an option to execute a script directly from the editor. You can also execute the scripts from the terminal using the following command:\npy build_dashboard.py\nThis assumes that you named your script build_dashboard.py and the command prompt’s current directory is the folder storing build_dashboard.py. You can change the current directory of the terminal using the cd command. For example you can use the following to move into C:/Users/:\ncd C:/Users/\nYou can also use full or relative paths from the current directory to the python script without changing the current working directory. For example if you start in your %userprofile% (C:/Users/[your username]) and the python script is stored at C:/Users/[your username]/python_projects/build_dashboard.py, you can execute the script with the following:\npy python_projects/build_dashboard.py"
  },
  {
    "objectID": "basic_setup.html#python",
    "href": "basic_setup.html#python",
    "title": "basic_setup",
    "section": "",
    "text": "Make sure python is installed on your computer."
  },
  {
    "objectID": "basic_setup.html#create-virtual-environment",
    "href": "basic_setup.html#create-virtual-environment",
    "title": "basic_setup",
    "section": "",
    "text": "For this example, we’re going to use a virtual environment to keep the package versions separate from what you have installed on your system 1. Open a command prompt and navigate to the folder you want to create dashboards in by running the following: shell    cd path/to/your/folder 2. Create and activate a virtual environment by running the same: ```shell # create a virtual environment python -m venv venv\n# for windows venv.bat\n# for linux or Mac (remove hashtag first) # source venv/bin/activate ```\n\nInstall the Power Bpy module:\n# install the Power Bpy module\npip install powerbpy\nWrite a script to create a dashboard. (This one’s up to you!)\nWhen you’re ready to create the dashboard, run the script by running the following in the command prompt window.\n\npython name_of_your_script.py"
  },
  {
    "objectID": "basic_setup.html#install-dependencies",
    "href": "basic_setup.html#install-dependencies",
    "title": "basic_setup",
    "section": "",
    "text": "Install python\nYou’ll need to install python. Here are some instructions\n\nInstall Power Bpy\nThe {powerbpy} package isn’t on pypi yet, so you’ll need to install it from github. Open a terminal and enter the following:\n\npy -m pip install git+https://github.com/Russell-Shean/powerbpy.git#egg=powerbpy     \nAfter the package is on pypi, you’ll be able to install it using this:\npy -m pip install powerbpy"
  },
  {
    "objectID": "basic_setup.html#executing-python-scripts",
    "href": "basic_setup.html#executing-python-scripts",
    "title": "basic_setup",
    "section": "",
    "text": "That’s all you need to install! To create the dashboards, you’ll need to either run the commands in a terminal, or use a text editor to save the commands in a a script. I recomend starting with a text editor, because as your dashboard grows more complex, it’ll be helpful to have everything saved in a script. Many text editors have an option to execute a script directly from the editor. You can also execute the scripts from the terminal using the following command:\npy build_dashboard.py\nThis assumes that you named your script build_dashboard.py and the command prompt’s current directory is the folder storing build_dashboard.py. You can change the current directory of the terminal using the cd command. For example you can use the following to move into C:/Users/:\ncd C:/Users/\nYou can also use full or relative paths from the current directory to the python script without changing the current working directory. For example if you start in your %userprofile% (C:/Users/[your username]) and the python script is stored at C:/Users/[your username]/python_projects/build_dashboard.py, you can execute the script with the following:\npy python_projects/build_dashboard.py"
  },
  {
    "objectID": "reference/add_background_image.html",
    "href": "reference/add_background_image.html",
    "title": "add_background_image",
    "section": "",
    "text": "add_background_image\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_background_img\nAdd a background image to a dashboard page\n\n\n\n\n\nadd_background_image.add_background_img(\n    dashboard_path,\n    page_id,\n    img_path,\n    alpha=100,\n    scaling_method='Fit',\n)\nAdd a background image to a dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the chart to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nimg_path\nstr\nThe path to the image you want to add. (Can be a relative path because the image is copied to the report folder). Allowed image types are whatever PBI allows manually, so probably at least jpeg and png\nrequired\n\n\nalpha\nint\nThe transparency of the background image. Must be a whole integer between 1 and 100.\n100\n\n\nscaling_method\nstr\nThe method used to scale the image available options include [“Fit”, ]\n'Fit'"
  },
  {
    "objectID": "reference/add_background_image.html#functions",
    "href": "reference/add_background_image.html#functions",
    "title": "add_background_image",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_background_img\nAdd a background image to a dashboard page\n\n\n\n\n\nadd_background_image.add_background_img(\n    dashboard_path,\n    page_id,\n    img_path,\n    alpha=100,\n    scaling_method='Fit',\n)\nAdd a background image to a dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the chart to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nimg_path\nstr\nThe path to the image you want to add. (Can be a relative path because the image is copied to the report folder). Allowed image types are whatever PBI allows manually, so probably at least jpeg and png\nrequired\n\n\nalpha\nint\nThe transparency of the background image. Must be a whole integer between 1 and 100.\n100\n\n\nscaling_method\nstr\nThe method used to scale the image available options include [“Fit”, ]\n'Fit'"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Python functions for building Power BI dashboards\n\n\n\ndashboard\n\n\n\npage",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#power-bpy",
    "href": "reference/index.html#power-bpy",
    "title": "Function reference",
    "section": "",
    "text": "Python functions for building Power BI dashboards\n\n\n\ndashboard\n\n\n\npage",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/update_diagramLayout.html",
    "href": "reference/update_diagramLayout.html",
    "title": "update_diagramLayout",
    "section": "",
    "text": "update_diagramLayout\nupdate_diagramLayout(dashboard_path, dataset_name, dataset_id)\nThis is an internal function to add a dataset to the diagramLayout file when a new dataset is added."
  },
  {
    "objectID": "reference/generate_bin_measures.html",
    "href": "reference/generate_bin_measures.html",
    "title": "generate_bin_measures",
    "section": "",
    "text": "generate_bin_measures\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_bin_measures\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\ngenerate_bin_measures.add_bin_measures(\n    dashboard_path,\n    dataset_name,\n    color_var,\n    percentile_bin_breaks,\n    color_palette,\n    filtering_var,\n    location_var,\n    data_filtering_condition=None,\n)\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndataset_name\nstr\nThe name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”.\nrequired\n\n\ndataset_id\nstr\nThe dataset’s UUID, this will be generated by the outer level function that calls create_tmdl().\nrequired\n\n\ndataset\nDataFrame\nThis is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\nrequired\n\n\ndata_filtering_condition\ndict\nThis is a key value pair for filtering long data. The key should be the column you want to look for and the value should be the value in that column that you want to filter for.For example if the original data has a column called metric with a variety of different metrics and you want to filter the dataset for only rows where the column is equal to “adj_rate”, you should provide the following {“metric”:“adj_rate”}\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ncol_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work. This function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions."
  },
  {
    "objectID": "reference/generate_bin_measures.html#functions",
    "href": "reference/generate_bin_measures.html#functions",
    "title": "generate_bin_measures",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_bin_measures\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\ngenerate_bin_measures.add_bin_measures(\n    dashboard_path,\n    dataset_name,\n    color_var,\n    percentile_bin_breaks,\n    color_palette,\n    filtering_var,\n    location_var,\n    data_filtering_condition=None,\n)\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndataset_name\nstr\nThe name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”.\nrequired\n\n\ndataset_id\nstr\nThe dataset’s UUID, this will be generated by the outer level function that calls create_tmdl().\nrequired\n\n\ndataset\nDataFrame\nThis is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\nrequired\n\n\ndata_filtering_condition\ndict\nThis is a key value pair for filtering long data. The key should be the column you want to look for and the value should be the value in that column that you want to filter for.For example if the original data has a column called metric with a variety of different metrics and you want to filter the dataset for only rows where the column is equal to “adj_rate”, you should provide the following {“metric”:“adj_rate”}\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ncol_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work. This function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions."
  },
  {
    "objectID": "reference/create_new_page.html",
    "href": "reference/create_new_page.html",
    "title": "create_new_page",
    "section": "",
    "text": "create_new_page\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_new_page\nCreate a new blank dashboard page\n\n\n\n\n\ncreate_new_page.add_new_page(\n    dashboard_path,\n    page_name,\n    title=None,\n    subtitle=None,\n    displayOption = \"FitToPage\"\n)\nCreate a new blank dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_name\nstr\nThe display name for the page you just created. This is differnt from the page_id which is only used internally.\nrequired\n\n\ntitle\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\nsub_title\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nrequired\n\n\ndisplayOption\nstr\nDefault way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize.\nFitToPage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nnew_page_id: The unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list."
  },
  {
    "objectID": "reference/create_new_page.html#functions",
    "href": "reference/create_new_page.html#functions",
    "title": "create_new_page",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_new_page\nCreate a new blank dashboard page\n\n\n\n\n\ncreate_new_page.add_new_page(\n    dashboard_path,\n    page_name,\n    title=None,\n    subtitle=None,\n    displayOption = \"FitToPage\"\n)\nCreate a new blank dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_name\nstr\nThe display name for the page you just created. This is differnt from the page_id which is only used internally.\nrequired\n\n\ntitle\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\nsub_title\nstr\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nrequired\n\n\ndisplayOption\nstr\nDefault way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize.\nFitToPage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\nnew_page_id: The unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list."
  },
  {
    "objectID": "reference/add_shape_map.html",
    "href": "reference/add_shape_map.html",
    "title": "add_shape_map",
    "section": "",
    "text": "add_shape_map(\n    dashboard_path,\n    page_id,\n    map_id,\n    data_source,\n    shape_file_path,\n    map_title,\n    location_var,\n    color_var,\n    color_palette,\n    height,\n    width,\n    x_position,\n    y_position,\n    add_legend=True,\n    static_bin_breaks=None,\n    percentile_bin_breaks=None,\n    filtering_var=None,\n    z_position=6000,\n    tab_order=-1001,\n)\nAdd a map to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the map to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nmap_id\nstr\nPlease choose a unique id to use to identify the map. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\ndata_source\nstr\nThe name of the dataset you want to use to build the map. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\nrequired\n\n\nshape_file_path\nstr\nA path to a shapefile that you want to use to build the map. This shape file will be added to the registered resources.\nrequired\n\n\nmap_title\nstr\nThe title you want to put above the map.\nrequired\n\n\nlocation_var\nstr\nThe name of the column in data_source that you want to use for the location variable on the map\nrequired\n\n\ncolor_var\nstr\nThe name of the column in data_source that you want to use for the color variable on the map\nrequired\n\n\nfiltering_var\nstr\nOptional. The name of a column in data source that you want to use to filter the color variable on the map. This must be supplied if providing percentile_bin_breaks. If you want to use percentiles without filtering (ie on static data), you should calculate the percentiles yourself and pass them to static_bin_breaks. Do not provide both static_bin_breaks and a filtering_var.\nNone\n\n\nstatic_bin_breaks\nlist\nThis should be a list of numbers that you want to use to create bins in your data. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. The function will create bins between the first and second number, second and third, third and fourth, etc. A filtering_var cannot be provided if static_bin_breaks is provided. Use percentile bin breaks instead.\nNone\n\n\ncolor_palatte\nlist\nA list of hex codes to use to color your data. There should be one fewer than the number of entries in static_bin_breaks\nrequired\n\n\nadd_legend\nbool\nTrue or False, would you like to add the default legend? (By default legend, I mean this function’s default, not the Power BI default)\nTrue\n\n\npercentile_bin_breaks\nlist\nThis should be a list of percentiles between 0 and 1 that you want to us to create bins in your data. If provided, a filtering_var must also be provided. This will create power BI measures that dynamically update when the data is filtered by things such as slicers. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. Here’s an example use case: to create 5 equal sized bins pass this list: [0,0.2,0.4,0.6,0.8,1]\nNone\n\n\nheight\nint\nHeight of map on the page\nrequired\n\n\nwidth\nint\nWidth of map on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the map on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the map on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) This function creates a new cloropleth map on a page.\n-1001"
  },
  {
    "objectID": "reference/add_shape_map.html#parameters",
    "href": "reference/add_shape_map.html#parameters",
    "title": "add_shape_map",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the map to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nmap_id\nstr\nPlease choose a unique id to use to identify the map. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\ndata_source\nstr\nThe name of the dataset you want to use to build the map. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\nrequired\n\n\nshape_file_path\nstr\nA path to a shapefile that you want to use to build the map. This shape file will be added to the registered resources.\nrequired\n\n\nmap_title\nstr\nThe title you want to put above the map.\nrequired\n\n\nlocation_var\nstr\nThe name of the column in data_source that you want to use for the location variable on the map\nrequired\n\n\ncolor_var\nstr\nThe name of the column in data_source that you want to use for the color variable on the map\nrequired\n\n\nfiltering_var\nstr\nOptional. The name of a column in data source that you want to use to filter the color variable on the map. This must be supplied if providing percentile_bin_breaks. If you want to use percentiles without filtering (ie on static data), you should calculate the percentiles yourself and pass them to static_bin_breaks. Do not provide both static_bin_breaks and a filtering_var.\nNone\n\n\nstatic_bin_breaks\nlist\nThis should be a list of numbers that you want to use to create bins in your data. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. The function will create bins between the first and second number, second and third, third and fourth, etc. A filtering_var cannot be provided if static_bin_breaks is provided. Use percentile bin breaks instead.\nNone\n\n\ncolor_palatte\nlist\nA list of hex codes to use to color your data. There should be one fewer than the number of entries in static_bin_breaks\nrequired\n\n\nadd_legend\nbool\nTrue or False, would you like to add the default legend? (By default legend, I mean this function’s default, not the Power BI default)\nTrue\n\n\npercentile_bin_breaks\nlist\nThis should be a list of percentiles between 0 and 1 that you want to us to create bins in your data. If provided, a filtering_var must also be provided. This will create power BI measures that dynamically update when the data is filtered by things such as slicers. There should be one more entry in the list than the number of bins you want and therefore the number of colors passed to the color_palette argument. Here’s an example use case: to create 5 equal sized bins pass this list: [0,0.2,0.4,0.6,0.8,1]\nNone\n\n\nheight\nint\nHeight of map on the page\nrequired\n\n\nwidth\nint\nWidth of map on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the map on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the map on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions) This function creates a new cloropleth map on a page.\n-1001"
  },
  {
    "objectID": "reference/add_slicer.html",
    "href": "reference/add_slicer.html",
    "title": "add_slicer",
    "section": "",
    "text": "add_slicer(\n    data_source,\n    column_name,\n    dashboard_path,\n    page_id,\n    slicer_id,\n    height,\n    width,\n    x_position,\n    y_position,\n    z_position=6000,\n    tab_order=-1001,\n    title=None,\n    text_align='left',\n    font_weight='bold',\n    font_size=32,\n    font_color='#000000',\n    background_color=None,\n    parent_group_id=None,\n)\nAdd a slicer to a page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_source\nstr\nThis is the name of the dataset that you want to use to populate the slicer with\nrequired\n\n\ncolumn_name\nstr\nThis is the name of the measure (or variable) name you want to use to populate the slicer with\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the slicer to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nslicer_id\nstr\nPlease choose a unique id to use to identify the slicer. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of slicer on the page\nrequired\n\n\nwidth\nint\nWidth of slicer on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the slicer on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the slicer on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\ntitle\nstr\nAn optional title to add to the slicer.\nNone\n\n\ntext_align\nstr\nHow would you like the text aligned (available options: “left”, “right”, “center”)\n'left'\n\n\nfont_weight\nstr\nThis is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”]\n'bold'\n\n\nfont_size\nint\nThe font size in pts. Must be a whole integer. Defaults to 32 pt\n32\n\n\nfont_color\nstr\nHex code for the font color you’d like to use. Defaults to black (#000000)\n'#000000'\n\n\nbackground_color\nstr\nHex code for the background color of the slicer. Defaults to None (transparent)\nNone\n\n\nparent_group_id\nstr\nThis should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group. This function creates a new slicer on a page.\nNone"
  },
  {
    "objectID": "reference/add_slicer.html#parameters",
    "href": "reference/add_slicer.html#parameters",
    "title": "add_slicer",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata_source\nstr\nThis is the name of the dataset that you want to use to populate the slicer with\nrequired\n\n\ncolumn_name\nstr\nThis is the name of the measure (or variable) name you want to use to populate the slicer with\nrequired\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\npage_id\nstr\nThe unique id for the page you want to add the slicer to. If you used this package’s functions it will be in the format page1, page2, page3, page4, etc. If you manually created the page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\nrequired\n\n\nslicer_id\nstr\nPlease choose a unique id to use to identify the slicer. PBI defaults to using a UUID, but it’d probably be easier if you choose your own id.\nrequired\n\n\nheight\nint\nHeight of slicer on the page\nrequired\n\n\nwidth\nint\nWidth of slicer on the page\nrequired\n\n\nx_position\nint\nThe x coordinate of where you want to put the slicer on the page. Origin is page’s top left corner.\nrequired\n\n\ny_position\nint\nThe y coordinate of where you want to put the slicer on the page. Origin is page’s top left corner.\nrequired\n\n\nz_position\nint\nThe z index for the visual. (Larger number means more to the front, smaller number means more to the back). Defaults to 6000\n6000\n\n\ntab_order\nint\nThe order which the screen reader reads different elements on the page. Defaults to -1001 for now. (I need to do more to figure out what the numbers correpond to. It should also be possible to create a function to automatically order this left to right top to bottom by looping through all the visuals on a page and comparing their x and y positions)\n-1001\n\n\ntitle\nstr\nAn optional title to add to the slicer.\nNone\n\n\ntext_align\nstr\nHow would you like the text aligned (available options: “left”, “right”, “center”)\n'left'\n\n\nfont_weight\nstr\nThis is an option to change the font’s weight. Defaults to bold. Available options include: [“bold”]\n'bold'\n\n\nfont_size\nint\nThe font size in pts. Must be a whole integer. Defaults to 32 pt\n32\n\n\nfont_color\nstr\nHex code for the font color you’d like to use. Defaults to black (#000000)\n'#000000'\n\n\nbackground_color\nstr\nHex code for the background color of the slicer. Defaults to None (transparent)\nNone\n\n\nparent_group_id\nstr\nThis should be a valid id code for another power BI visual. If supplied the current visual will be nested inside the parent group. This function creates a new slicer on a page.\nNone"
  },
  {
    "objectID": "reference/create_tmdl.html",
    "href": "reference/create_tmdl.html",
    "title": "create_tmdl",
    "section": "",
    "text": "create_tmdl(dashboard_path, dataset_name, dataset_id, dataset)\nAn internally called function that creates a TMDL file from a pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndataset_name\nstr\nThe name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”.\nrequired\n\n\ndataset_id\nstr\nThe dataset’s UUID, this will be generated by the outer level function that calls create_tmdl().\nrequired\n\n\ndataset\nDataFrame\nThis is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\n\ncol_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work. This function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions."
  },
  {
    "objectID": "reference/create_tmdl.html#parameters",
    "href": "reference/create_tmdl.html#parameters",
    "title": "create_tmdl",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndashboard_path\nstr\nThe path where the dashboard files are stored. (This is the top level directory containing the .pbip file and Report and SemanticModel folders).\nrequired\n\n\ndataset_name\nstr\nThe name of the dataset. This should be the basename of the original file without the extension. For example if you loaded “%userprofile%/documents/datasets/birds.csv”, the dataset name would be “birds”.\nrequired\n\n\ndataset_id\nstr\nThe dataset’s UUID, this will be generated by the outer level function that calls create_tmdl().\nrequired\n\n\ndataset\nDataFrame\nThis is a pandas dataframe of the csv’s content. The pd.read_csv() function is called by the outer level function that calls create_tmdl().\nrequired"
  },
  {
    "objectID": "reference/create_tmdl.html#returns",
    "href": "reference/create_tmdl.html#returns",
    "title": "create_tmdl",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\n\ncol_attributes: A dictionary containing the name and type of all the columns in the dataset. This is needed to get the M code in the outer level function to work. This function loops through all the dataframe’s columns, checks the column’s type (text, number, date), and generates the appropriate TMDL column definition for that type. Dates will only be recocognized as dates if they are in the format (YYYY-MM-DD) i.e. (1999-12-31). If your date is in another format please change in python before calling the add_csv functions."
  },
  {
    "objectID": "reference/dashboard.html",
    "href": "reference/dashboard.html",
    "title": "dashboard",
    "section": "",
    "text": "dashboard\n\n\n\n\n\nName\nDescription\n\n\n\n\nDashboard\nA python class used to model a power BI dashboard project\n\n\n\n\n\ndashboard.Dashboard(file_path)\nA python class used to model a power BI dashboard project\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile_path\n\nThe path to the directory where you want to store the new dashboard. The directory should not exist yet. The basename of the directory will also be the report name.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nTo create a new dashboard instance, use either Dashboard.create(dashboard_path) to create a new dashboard or Dashboard.create(dashboard_path) to load an existing dashboard.\nThe dashboard uses a .pbip/.pbir format with TMDL enabled.\nTo publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing\nThese annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions.\n(.pbip uses mimified json by default and throws an error when it’s given unpacked json).\nTime intelligence and relationship autodection are turned off by default\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_blob_csv\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\nadd_local_csv\nAdd a locally stored CSV file to a dashboard\n\n\nadd_tmdl\nAdd a locally stored TMDL file to the dashboard\n\n\ncreate\nA python class used to model a power BI dashboard project\n\n\nget_measures_list\nReturns a list of DAX measures in the report\n\n\nlist_pages\nList all pages associated with a dashboard\n\n\nload\nLoad an existing dashboard from a file path\n\n\nload_page\nLoad an existing page\n\n\nnew_page\nCreate a new blank dashboard page\n\n\n\n\n\ndashboard.Dashboard.add_blob_csv(\n    data_path,\n    account_url,\n    blob_name,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    sas_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naccount_url\n\nThe url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field\nrequired\n\n\nblob_name\n\nThe name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field.\nrequired\n\n\ndata_path\n\nThe relative path to the file you want to load from the blob. It should be relative to blob_name\nrequired\n\n\ntenant_id\n\nThe tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default).\nNone\n\n\nuse_saved_storage_key\n\nThis optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD.\nFalse\n\n\nsas_url\n\nA limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature”\nNone\n\n\nstorage_account_key\n\nIt is not recommended to use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\nDO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead.\nThis function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file.\nDashboards created with the Dashboard.create() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this.\n\n\n\n\ndashboard.Dashboard.add_local_csv(data_path)\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_path\n\nThe path where the csv file is stored. Can be a relative path. The M code requires a full path, but this python function will help you resolve any valid relative paths to an absolute path.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndataset\nclass\nAn instantce of the LocalCsv dataset class\n\n\n\n\n\n\nThis function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset.\n\n\n\n\ndashboard.Dashboard.add_tmdl(data_path=None, add_default_datetable=True)\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_path\n\nThe path where the tmdl file is stored.\nNone\n\n\nadd_default_datetable\n\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence\nTrue\n\n\n\n\n\n\n\nTMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset.\nIn practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale\nPotential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\n\n\n\n\n\ndashboard.Dashboard.create(file_path)\nA python class used to model a power BI dashboard project\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile_path\n\n\nrequired\n\n\nThe\n\n\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nTo create a new dashboard instance, use this function Dashboard.create(dashboard_path)\nTo load an existing dashboard use Dashboard.load(dashboard_path)\n\n\n\n\n\ndashboard.Dashboard.get_measures_list(\n    export_type='markdown',\n    output_file_path='',\n    starts_with='formatString:',\n)\nReturns a list of DAX measures in the report\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexport_type\n\nExport type for the function result: export to a .xlsx file (parameter value ‘xlsx’), to a .csv file (parameter value ‘csv’), or output in markdown format without saving (parameter value ‘markdown’’)\n'markdown'\n\n\noutput_file_path\n\nThe path for export (if the export_type value is specified as ‘.xlsx’ or ‘.csv’). Example: “D:/PBI project/blank_template/”, export result will be stored as “D:/PBI project/blank_template/blank_template - measures.xlsx””\n''\n\n\nstarts_with\n\nTechnical parameter for measure selection. Default options is ‘formatString:’, for older reports without formatString in the measure definition try using ‘lineageTag:’ instead\n'formatString:'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nReturns a list of DAX measures used in the report in the specified format (see param export_type): the measure name, its definition, the table it belongs to, and the description (if available); prints \"Measures not found\" otherwise\n\n\n\n\n\n\n\n\ndashboard.Dashboard.list_pages()\nList all pages associated with a dashboard\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nNone\n\n\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\npages\nlist\nThis returns a list of all the page_ids in the dashboard\n\n\n\n\n\n\nUse this function to get a list of all the page_ids associated with a dashboard. The list of page_ids is determined from reading the “test_dashboard/test_dashboard.Report/definition/pages/pages.json” file. This assumes that page_ids listed in the page.json match the folder names.\n\n\n\n\ndashboard.Dashboard.load(file_path)\nLoad an existing dashboard from a file path\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile_path\n\n\nrequired\n\n\nThe\n\n\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nTo load an existing dashboard, use this function Dashboard.load(dashboard_path)\nTo create a new dashboard instance use Dashboard.create(dashboard_path)\n\n\n\n\n\ndashboard.Dashboard.load_page(page_id)\nLoad an existing page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npage_id\n\nThe page_id of the page you’d like to load.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n_Page\nclass\nThis returns an instance of the Page class corresponding to the page you just loaded.\n\n\n\n\n\n\nYou should use this function to load an existing page from a power BI report as an instance of the Page class. This lets you call Page methods such as those that add visuals. To list all page ids you can use Dashboard.list_pages(). You can also check the .pbip folder structure to find the page ids\n\n\n\n\ndashboard.Dashboard.new_page(\n    page_name,\n    title=None,\n    subtitle=None,\n    display_option='FitToPage',\n)\nCreate a new blank dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npage_name\n\nThe display name for the page you just created. This is different from the page_id which is only used internally.\nrequired\n\n\ntitle\n\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\nsubtitle\n\nSubtitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\ndisplay_option\n\nDefault way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize\n'FitToPage'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nnew_page_id\nstr\nThe unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\n\n\n\n\n\n\nIn order to reference the page to add visuals to it later, you’ll need to remember what order you created the pages in. The first page that is created when you first call create_new_dashboard() is called “page1”, the next page you create is called “page2”, the page after that is called “page3” etc. (I’m going to convert the functions to classes and methods soon at which point this paragraph will become irrelevant).\nIn our example, I’ll create a new page called “Bee Colonies” and then we’ll add a title called “The bees are in trouble!” and a subtitle below it called “We’re losing bee colonies”. The title and subtitle arguments make a best guess about the best font and position for the text boxes that make up the title and subtitle. These arguments are optional, so if you don’t want a title or subtitle, just leave the argument blank. If you want the title to have a different font, style, position, etc from the default use the add_text_box() function. Here’s the code to create a new (mostly blank) page:\n    my_dashboard.new_page(page_name = \"Bee Colonies\",\n               title= \"The bees are in trouble!\",\n               subtitle = \"We're losing bee colonies\")\nHere’s what the new page looks like in Power BI Desktop",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "dashboard"
    ]
  },
  {
    "objectID": "reference/dashboard.html#classes",
    "href": "reference/dashboard.html#classes",
    "title": "dashboard",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nDashboard\nA python class used to model a power BI dashboard project\n\n\n\n\n\ndashboard.Dashboard(file_path)\nA python class used to model a power BI dashboard project\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile_path\n\nThe path to the directory where you want to store the new dashboard. The directory should not exist yet. The basename of the directory will also be the report name.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nTo create a new dashboard instance, use either Dashboard.create(dashboard_path) to create a new dashboard or Dashboard.create(dashboard_path) to load an existing dashboard.\nThe dashboard uses a .pbip/.pbir format with TMDL enabled.\nTo publish this type of dashboard you will need to either use git enabled workspaces OR convert to a .pbit template and then to a .pbix file before publishing\nThese annoyances are worth it because the .pbir + TMDL format is the only one that allows real version control and programatic manipulation of the report using these functions.\n(.pbip uses mimified json by default and throws an error when it’s given unpacked json).\nTime intelligence and relationship autodection are turned off by default\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_blob_csv\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\nadd_local_csv\nAdd a locally stored CSV file to a dashboard\n\n\nadd_tmdl\nAdd a locally stored TMDL file to the dashboard\n\n\ncreate\nA python class used to model a power BI dashboard project\n\n\nget_measures_list\nReturns a list of DAX measures in the report\n\n\nlist_pages\nList all pages associated with a dashboard\n\n\nload\nLoad an existing dashboard from a file path\n\n\nload_page\nLoad an existing page\n\n\nnew_page\nCreate a new blank dashboard page\n\n\n\n\n\ndashboard.Dashboard.add_blob_csv(\n    data_path,\n    account_url,\n    blob_name,\n    tenant_id=None,\n    use_saved_storage_key=False,\n    sas_url=None,\n    storage_account_key=None,\n    warnings=True,\n)\nAdd a csv file store in a ADLS blob container to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naccount_url\n\nThe url to your Azure storage account. It should be in the format of https://.blob.core.windows.net/. You can find it in Azure Storage Explorer by clicking on the storage account and then looking at the blob endpoint field\nrequired\n\n\nblob_name\n\nThe name of the blob container. In Azure Storage Explorer, click on the storage account, then inside “Blob Containers” will be all your blob containers. Use the node dislay name field.\nrequired\n\n\ndata_path\n\nThe relative path to the file you want to load from the blob. It should be relative to blob_name\nrequired\n\n\ntenant_id\n\nThe tenant id of the tenant where your storage account is stored. This field is only used with browser authentication. (The default).\nNone\n\n\nuse_saved_storage_key\n\nThis optional argument tells python to look in your system’s default credential manager for an Azure Storage Account token and prompt the user to add one if it’s not there. USE WITH CAUTION, THE STORAGE ACCOUNT TOKENS ALLOW FOR A MASSIVE AMOUNT OF ACCESS. CONSIDER USING SAS URLS OR INTERACTIVE BROWSER AUTHENTICATION INSTEAD.\nFalse\n\n\nsas_url\n\nA limited time single access url scoped to just the file you want to grant read access to. To generate one from Azure Storage Explorer, right click on the file you want and then choose “Get Shared Access Signature”\nNone\n\n\nstorage_account_key\n\nIt is not recommended to use this when running this function on a local computer. Hardcoding credentials into code is SUPER BAD practice. Please set use_saved_storage_key to true instead. It will store the key securely in your operating system’s credential manger. You should only pass a storage account key to the function if you are running this code in a cloud environment such as databricks and using that cloud platform’s secure secret manager. (Something like Github Secrets or Azure Key Vault)\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\nDO NOT HARD CODE CREDENTIALS. Use the use_saved_storage_key option instead.\nThis function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset. Other dumb things: If you get an error when trying to open the .pbip file try changing the combatibility version to 1567 in the semanticmodel &gt; definition &gt; database.tmdl file.\nDashboards created with the Dashboard.create() function start with the compatibility version set to 1567, so you should only have this problem with manually created dashboards. I may eventually add an automatic fix for this.\n\n\n\n\ndashboard.Dashboard.add_local_csv(data_path)\nAdd a locally stored CSV file to a dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_path\n\nThe path where the csv file is stored. Can be a relative path. The M code requires a full path, but this python function will help you resolve any valid relative paths to an absolute path.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndataset\nclass\nAn instantce of the LocalCsv dataset class\n\n\n\n\n\n\nThis function creates custom M code and is therefore more picky than pandas or Power BI desktop. The csv file should probably not have row numbers. (Any column without a column name will be renamed to “probably_an_index_column”) NA values must display as “NA” or “null” not as N/A. If the data is malformed in Power BI, try cleaning it first in python and then rerunning this function.\nThis function creates a new TMDL file defining the dataset in TMDL format and also in M code. The DiagramLayout and Model.tmdl files are updated to include refrences to the new dataset.\n\n\n\n\ndashboard.Dashboard.add_tmdl(data_path=None, add_default_datetable=True)\nAdd a locally stored TMDL file to the dashboard\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata_path\n\nThe path where the tmdl file is stored.\nNone\n\n\nadd_default_datetable\n\nDo you want the TMDL file you add to be our team’s custom date table? This will allow you to create your own date heirarchies instead of using time intelligence\nTrue\n\n\n\n\n\n\n\nTMDL is a data storage format automatically created by power BI consisting of a table and column definitions and the M code used to generate the dataset.\nIn practice this means that you can copy datasets between dashboards. You can use this function to automatically copy the TMDL files at scale\nPotential pitfalls: M needs full paths to load data. If the new dashboard doesn’t have access to the same data as the old dashboard, the data copying may fail.\n\n\n\n\n\ndashboard.Dashboard.create(file_path)\nA python class used to model a power BI dashboard project\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile_path\n\n\nrequired\n\n\nThe\n\n\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nTo create a new dashboard instance, use this function Dashboard.create(dashboard_path)\nTo load an existing dashboard use Dashboard.load(dashboard_path)\n\n\n\n\n\ndashboard.Dashboard.get_measures_list(\n    export_type='markdown',\n    output_file_path='',\n    starts_with='formatString:',\n)\nReturns a list of DAX measures in the report\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexport_type\n\nExport type for the function result: export to a .xlsx file (parameter value ‘xlsx’), to a .csv file (parameter value ‘csv’), or output in markdown format without saving (parameter value ‘markdown’’)\n'markdown'\n\n\noutput_file_path\n\nThe path for export (if the export_type value is specified as ‘.xlsx’ or ‘.csv’). Example: “D:/PBI project/blank_template/”, export result will be stored as “D:/PBI project/blank_template/blank_template - measures.xlsx””\n''\n\n\nstarts_with\n\nTechnical parameter for measure selection. Default options is ‘formatString:’, for older reports without formatString in the measure definition try using ‘lineageTag:’ instead\n'formatString:'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nReturns a list of DAX measures used in the report in the specified format (see param export_type): the measure name, its definition, the table it belongs to, and the description (if available); prints \"Measures not found\" otherwise\n\n\n\n\n\n\n\n\ndashboard.Dashboard.list_pages()\nList all pages associated with a dashboard\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nNone\n\n\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\npages\nlist\nThis returns a list of all the page_ids in the dashboard\n\n\n\n\n\n\nUse this function to get a list of all the page_ids associated with a dashboard. The list of page_ids is determined from reading the “test_dashboard/test_dashboard.Report/definition/pages/pages.json” file. This assumes that page_ids listed in the page.json match the folder names.\n\n\n\n\ndashboard.Dashboard.load(file_path)\nLoad an existing dashboard from a file path\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile_path\n\n\nrequired\n\n\nThe\n\n\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nTo load an existing dashboard, use this function Dashboard.load(dashboard_path)\nTo create a new dashboard instance use Dashboard.create(dashboard_path)\n\n\n\n\n\ndashboard.Dashboard.load_page(page_id)\nLoad an existing page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npage_id\n\nThe page_id of the page you’d like to load.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n_Page\nclass\nThis returns an instance of the Page class corresponding to the page you just loaded.\n\n\n\n\n\n\nYou should use this function to load an existing page from a power BI report as an instance of the Page class. This lets you call Page methods such as those that add visuals. To list all page ids you can use Dashboard.list_pages(). You can also check the .pbip folder structure to find the page ids\n\n\n\n\ndashboard.Dashboard.new_page(\n    page_name,\n    title=None,\n    subtitle=None,\n    display_option='FitToPage',\n)\nCreate a new blank dashboard page\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npage_name\n\nThe display name for the page you just created. This is different from the page_id which is only used internally.\nrequired\n\n\ntitle\n\nTitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\nsubtitle\n\nSubtitle to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\nNone\n\n\ndisplay_option\n\nDefault way to display the page for end users (View -&gt; Page View options in Power BI). Possible options: FitToPage, FitToWidth, ActualSize\n'FitToPage'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nnew_page_id\nstr\nThe unique id for the page you just created. If you used this function it will be in the format page1, page2, page3, page4, etc. If you manually create a page it will be a randomly generated UUID. To find a page’s page id, consult the report &gt; definition&gt; pages &gt; page.json file and look in the page order list.\n\n\n\n\n\n\nIn order to reference the page to add visuals to it later, you’ll need to remember what order you created the pages in. The first page that is created when you first call create_new_dashboard() is called “page1”, the next page you create is called “page2”, the page after that is called “page3” etc. (I’m going to convert the functions to classes and methods soon at which point this paragraph will become irrelevant).\nIn our example, I’ll create a new page called “Bee Colonies” and then we’ll add a title called “The bees are in trouble!” and a subtitle below it called “We’re losing bee colonies”. The title and subtitle arguments make a best guess about the best font and position for the text boxes that make up the title and subtitle. These arguments are optional, so if you don’t want a title or subtitle, just leave the argument blank. If you want the title to have a different font, style, position, etc from the default use the add_text_box() function. Here’s the code to create a new (mostly blank) page:\n    my_dashboard.new_page(page_name = \"Bee Colonies\",\n               title= \"The bees are in trouble!\",\n               subtitle = \"We're losing bee colonies\")\nHere’s what the new page looks like in Power BI Desktop",
    "crumbs": [
      "Reference",
      "Power Bpy",
      "dashboard"
    ]
  },
  {
    "objectID": "example_dashboards/Test Dashboard/Testing Dashboard.html",
    "href": "example_dashboards/Test Dashboard/Testing Dashboard.html",
    "title": "Recreate my testing dashboard",
    "section": "",
    "text": "This example shows how I create the dashboard I use for testing the module. It isn’t pretty but it shows a good overview of everything that is currently possible to create using the module. You’ll learn how to:\n- create a new dashboard\n- add pages to the dashboard\n- add visual elements such as maps and charts to the pages"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/Testing Dashboard.html#create-a-new-dashboard",
    "href": "example_dashboards/Test Dashboard/Testing Dashboard.html#create-a-new-dashboard",
    "title": "Recreate my testing dashboard",
    "section": "Create a new dashboard",
    "text": "Create a new dashboard\nTo create a new dashboard, you’ll need to provide a file path to a folder as argument:\nIf you want to create a dashboard called test_dashboard in a folder called C:/Users/Russ/PBI_projects, here’s what the code should look like\n# Import the package\nfrom powerbpy import Dashboard\n\nmy_dashboard = Dashboard.create(\"C:/Users/Russ/PBI_projects/test_dashboard\")\nIf everything worked, the function should have created the following files:\n\nYou can open the test_dashboard.pbip file in Power BI desktop normally. (Although you will probably need to turn on these preview features. )"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-a-new-page",
    "href": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-a-new-page",
    "title": "Recreate my testing dashboard",
    "section": "Add a new page",
    "text": "Add a new page\nDashboards don’t start with any pages until you add them. To add a new page, you’ll need to provide the following arguments:\n1. page_name - This is display name for the page. (This is different from the page_id).\nYou can also provide the following optional arguments:\n2. title - Title to put at the top of the page. This under the hood calls the add_text_box() function. If you would like more control over the title’s appearance use that function instead.\n3. subtitle - This is similar to the title, but it goes below the title. If you would like more control use the add_text_box() function\n4. displayOption - I’m honestly not sure what this does, someone who understands Power BI better than me will have to let me know ;). Currently the option is set to FitToPage and other options include FitToWidth and ActualSize.\nIn our example, I’ll create a new page called “Bee Colonies” and then we’ll add a title called “The bees are in trouble!” and a subtitle below it called “We’re losing bee colonies”. The title and subtitle arguments make a best guess about the best font and position for the text boxes that make up the title and subtitle. These arguments are optional, so if you don’t want a title or subtitle, just leave the argument blank. If you want the title to have a different font, style, position, etc from the default use the add_text_box() function.\nHere’s the code to create a new (mostly blank) page:\npage1 = my_dashboard.new_page(page_name = \"Bee Colonies\",\n                       title= \"The bees are in trouble!\",\n                       subtitle = \"We're losing bee colonies\")\nHere’s what the new page looks like in Power BI Desktop"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-background-image",
    "href": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-background-image",
    "title": "Recreate my testing dashboard",
    "section": "Add background image",
    "text": "Add background image\nHere’s how you can add a background image to a page. To add the image, you’ll need to provide the following required arguments:\n1. img_path - This is the path (relative or full) to the image you want to add to the dashboard\nThere are two additional optional arguments:\n2. alpha - This is the image’s transparency with 0 is fully transparent and 100 is full non-transparent (defaults to 100 )\n3. scaling_method - This tells Power BI how to scale the image (defaults to “Fit” which fits the image to the page)\nHere’s some example code that adds a new background image to the Bee Colonies page:\npage1.add_background_image(img_path = \"examples/data/Taipei_skyline_at_sunset_20150607.jpg\", \n                   alpha = 51,\n                   scaling_method = \"Fit\")            \nAnd here’s what the dashboard looks like, now that we’ve added a background image:\n\n\n\nBackground Image Example"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-a-dataset",
    "href": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-a-dataset",
    "title": "Recreate my testing dashboard",
    "section": "Add a dataset",
    "text": "Add a dataset\nFor most dashboards, you’ll want to add visuals that help users visualize the data. Before you can start adding visuals, you’ll need to add datasets. Here’s how you can add a dataset locally stored on your computer as a csv file to your dashboard. This method is attached to the Dashboard not the Page because the same dataset can be used across multiple pages and visuals. You’ll need to provide the following arguments:\n1. data_path = The location of the csv file that you want to add. Can be a relative or full path\nHere’s some example code:\nmy_dashboard.add_local_csv(data_path = \"examples/data/colony.csv\")"
  },
  {
    "objectID": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-a-chart",
    "href": "example_dashboards/Test Dashboard/Testing Dashboard.html#add-a-chart",
    "title": "Recreate my testing dashboard",
    "section": "Add a chart",
    "text": "Add a chart\nHere’s how you can add a bar chart to your dashboard. To add the chart you’ll need to provide the following required arguments:\n1. visual_id - Give your chart a unique id that you’ll remember. (Power BI’s default is to generate a UUID which will be unique, but also impossible to remember. This id needs to be different from all the other visual id’s in the dashboard. It will also be the name of the file inside the Power BI project folder. )\n2. chart_type - This is the type of chart to build on the page. I’ve only ever tried this with the columnCart option, the options I currently know about include: : [\"columnChart\",\"barChart\", \"clusteredBarChart\"]\n3. data_source - The name of the data source you want to use for the visual. This corresponds to the dataset_name field in the add data functions. You must have already loaded the data to the dashboard.\n4. chart_title - Give your chart an informative title! This will display on the dashboard as part of the chart.\n5. x_axis_title - This is the text that will label the x axis\n6. y_axis_title - This is the text that will label the y axis\n7. x_axis_var - This is the variable to use for the x axis\n8. y_axis_var - This is the variable to use for the y axis\n9. y_axis_var_aggregation_type - This is how values in the y axis should be grouped and processed. The default is sum (total value of y for each grouping of x)\n10. x_position - The x coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\n11. y_position - The y coordinate of where you want to put the chart on the page. Origin is page’s top left corner.\n12. height - Height of chart on the page\n13. width - Width of chart on the page\nHere’s some example code that adds a bar chart showing bee colonies lost per year:\npage1.add_chart(visual_id = \"colonies_lost_by_year\", \n          chart_type = \"columnChart\",\n          data_source = \"colony\",\n          chart_title = \"Number of Bee Colonies Lost per Year\",\n          x_axis_title = \"Year\",\n          y_axis_title = \"Number of Colonies\",\n          x_axis_var = \"year\",\n          y_axis_var = \"colony_lost\",\n          y_axis_var_aggregation_type = \"Sum\",\n          x_position = 23,\n          y_position = 158,\n          height = 524,\n          width = 603)"
  }
]